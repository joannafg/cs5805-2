[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my blog, a personal journey through the intricate and fascinating world of Machine Learning. My name is Ziming ‚ÄòJoanna‚Äô Fang, and I‚Äôm thrilled to have you join me in exploring various aspects of this dynamic field.\nCurrently pursuing my Master‚Äôs in Computer Science and Applications at Virginia Tech, I have a solid background in computer science and a keen interest in the practical applications of machine learning. This blog is not just a platform for sharing knowledge but also a reflection of my passion for understanding and leveraging the power of data and algorithms.\nHere‚Äôs what you can expect from my blog:\n\nProbability Theory and Random Variables: We‚Äôll start with the basics, exploring how probability theory and random variables form the foundation of machine learning. Expect deep dives into theory, practical examples, and intriguing problems.\nClustering: Clustering algorithms are pivotal in understanding data segmentation. I‚Äôll share insights on various clustering methods, their applications, and their role in data analysis.\nLinear and Nonlinear Regression: A journey through the realm of regression analysis, covering both linear and nonlinear approaches. I‚Äôll elucidate these concepts with real-world examples and hands-on coding.\nClassification: Delve into the world of classification algorithms. I‚Äôll break down complex concepts into digestible content, making it easier to understand how these algorithms categorize data.\nAnomaly/Outlier Detection: We‚Äôll explore the techniques used to identify anomalies in data sets, an important aspect of data analysis and security.\n\nEach post will be enriched with machine learning code snippets and at least one data visualization, ensuring a comprehensive and practical learning experience.\nI‚Äôm building this blog with Quarto and hosting it on GitHub Pages. This approach aligns with my belief in transparency, accessibility, and the power of open-source tools. You‚Äôll find my blog not just informative but also a testament to the power of programmatic website creation.\nOutside of academics, my experience as a Software Engineer at Avocado LLC and as a Research Assistant at the Mind Music Machine Lab has equipped me with a unique blend of skills. Whether it‚Äôs automating PDF news article processing with Python and ChatGPT, or applying sentiment extraction programs for emotional sonification in storytelling, I‚Äôve always been at the intersection of innovation and practicality.\nSo, whether you‚Äôre a fellow machine learning enthusiast, a curious learner, or someone interested in the intersection of data and technology, I invite you to join me on this enlightening journey. Let‚Äôs explore the world of machine learning together!\nHappy reading and learning! Ziming ‚ÄòJoanna‚Äô Fang üåüü§ñüìä"
  },
  {
    "objectID": "posts/testPost/index.html",
    "href": "posts/testPost/index.html",
    "title": "Test",
    "section": "",
    "text": "This is a test post. This is to test changes were deployed : D ‚Äî- 12:21PM This is to test changes were deployed : D ‚Äî- 1:05PM\nHere‚Äôs a simple Python code snippet:\nprint(\"Hello, world 123!\")\n\nHello, world 123!\nimport sys\n!{sys.executable} -m pip install numpy\n!{sys.executable} -m pip install matplotlib\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: numpy in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (1.26.2)\nWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\nYou should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: matplotlib in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (3.8.2)\nRequirement already satisfied: pillow&gt;=8 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.1.0)\nRequirement already satisfied: numpy&lt;2,&gt;=1.21 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.26.2)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: importlib-resources&gt;=3.2.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.1.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.45.1)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: packaging&gt;=20.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (23.2)\nRequirement already satisfied: cycler&gt;=0.10 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: zipp&gt;=3.1.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from importlib-resources&gt;=3.2.0-&gt;matplotlib) (3.17.0)\nRequirement already satisfied: six&gt;=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.15.0)\nWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\nYou should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\n\n\n\n\n\nFigure¬†1: A line plot on a polar axis\n-Joanna"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2023\n\n\nTristan O‚ÄôMalley\n\n\n\n\n\n\n  \n\n\n\n\nTest\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\ntest\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2023\n\n\nJoanna Fang\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nProbability Theory and Random Variables\n\n\n\n\n\n\n\nml\n\n\ncode\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2023\n\n\nJoanna Fang\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/testPost/index.html#introduction",
    "href": "posts/testPost/index.html#introduction",
    "title": "Test",
    "section": "Introduction",
    "text": "Introduction\nIn the realm of probability and statistics, the Poisson distribution is a fundamental concept, often used to model the frequency of various types of events. This blog post aims to demystify the Poisson distribution by tracing its roots back to the Binomial distribution, and then, applying it to a real-world scenario: analyzing the number of emails received per hour."
  },
  {
    "objectID": "posts/testPost/index.html#the-theoretical-underpinnings",
    "href": "posts/testPost/index.html#the-theoretical-underpinnings",
    "title": "Test",
    "section": "The Theoretical Underpinnings",
    "text": "The Theoretical Underpinnings\n\nBinomial Distribution: A Starting Point\nThe journey begins with the Binomial distribution, which calculates the probability of obtaining a certain number of successes in a fixed number of independent trials. It‚Äôs expressed as:\n[ P(X = k) = p^k (1-p)^{n-k} ]\nwhere: - ( n ) is the number of trials - ( k ) is the number of successes - ( p ) is the probability of success on a single trial.\n\n\nTransitioning to Poisson\nThe Poisson distribution emerges as a special case of the Binomial distribution, particularly when the number of trials is large (( n )), and the probability of success is small (( p )), while their product (( = np )) remains constant.\nThe Poisson distribution is given by:\n[ P(X = k) = ]\nwhere ( ) is the mean number of successes over the interval.\n\n\nGraphical Interpretation\nBy graphically comparing the two distributions for varying values of ( n ) and ( p ), we can observe how the Binomial distribution converges to the Poisson distribution under these conditions."
  },
  {
    "objectID": "posts/testPost/index.html#practical-application-email-analysis",
    "href": "posts/testPost/index.html#practical-application-email-analysis",
    "title": "Test",
    "section": "Practical Application: Email Analysis",
    "text": "Practical Application: Email Analysis\nNow, let‚Äôs apply this knowledge to a practical scenario: estimating the number of emails one might receive in an hour.\n\nSetting Up the Experiment\nFor this experiment, we assume an average of 5 emails per hour. This rate (( )) serves as our parameter for the Poisson distribution.\n\n\nSimulating Email Receipt\nUsing a programming tool like Python, we can simulate the receipt of emails over a 24-hour period. The Poisson distribution will allow us to model the probability of receiving a certain number of emails each hour.\n\n\nVisualizing the Results\nThe simulation results can be visualized in a histogram, showing the frequency of hours with a specific number of emails. This graph provides a clear picture of the email distribution pattern over the course of a day."
  },
  {
    "objectID": "posts/testPost/index.html#conclusion-insights-and-applications",
    "href": "posts/testPost/index.html#conclusion-insights-and-applications",
    "title": "Test",
    "section": "Conclusion: Insights and Applications",
    "text": "Conclusion: Insights and Applications\nThis analysis not only deepens our understanding of the Poisson distribution but also demonstrates its practical utility in everyday scenarios. Whether it‚Äôs for planning resources in customer service or managing workload in IT support, the Poisson distribution offers valuable insights into event frequencies.\nUnderstanding statistical concepts like the Poisson distribution and their derivation from more fundamental principles enriches our ability to interpret and analyze the world around us. Stay tuned for more explorations into the exciting world of probability and statistics!"
  },
  {
    "objectID": "posts/probability/index.html",
    "href": "posts/probability/index.html",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "The Binomial distribution is a cornerstone of probability theory, serving as a foundation for more complex distributions, including the Poisson distribution. This section aims to clarify the basics of the Binomial distribution.\n\n\nThe Binomial distribution is a probability distribution that models the number of successes in a fixed number of independent trials, with each trial having the same probability of success. It is particularly useful in scenarios with two possible outcomes, often labeled as ‚Äúsuccess‚Äù and ‚Äúfailure.‚Äù\n\n\n\n\nNumber of Trials (\\(n\\)): This denotes the total number of independent trials or experiments.\nProbability of Success (\\(p\\)): The probability of achieving a successful outcome in an individual trial.\nNumber of Successes (\\(k\\)): The specific count of successful outcomes we are interested in.\n\n\n\n\nThe probability of observing exactly \\(k\\) successes in \\(n\\) trials is described by the Binomial formula: \\[ P(X = k) = \\binom{n}{k} p^k (1 - p)^{n - k} \\] Here, \\(\\binom{n}{k}\\) (pronounced ‚Äún choose k‚Äù) represents the number of ways to select \\(k\\) successes from \\(n\\) trials.\n\n\n\nConsider a scenario where you flip a coin 10 times. What is the probability of flipping exactly 4 heads? In this example: - \\(n = 10\\) (the total number of coin flips), - \\(p = 0.5\\) (the probability of flipping heads on any single coin flip), - \\(k = 4\\) (the number of heads we are trying to achieve).\nUsing the Binomial formula, the probability is: \\[ P(X = 4) = \\binom{10}{4} (0.5)^4 (1 - 0.5)^{10 - 4} \\]\n\n\n\nThe Binomial distribution is crucial in understanding binary outcomes across various fields such as psychology, medicine, and quality control. It provides a framework for scenarios with fixed trial numbers and clear success/failure outcomes. However, for large-scale or continuous-event contexts, the Poisson distribution becomes more relevant, as we will explore in subsequent sections.\n\n\n\n\nIn this section, we explore the intriguing relationship between the Binomial and Poisson distributions and how one transitions into the other under certain conditions. This transition is particularly important in scenarios involving a large number of trials and a small probability of success.\n\n\nThe Binomial distribution effectively models situations with a fixed number of independent trials and a constant probability of success in each trial. However, when we consider scenarios where the number of trials (\\(n\\)) is very large, and the probability of success in each trial (\\(p\\)) is very small, the Binomial distribution becomes less practical for calculations. This is where the Poisson distribution becomes relevant.\nThe key to this transition lies in the product of \\(n\\) and \\(p\\). As \\(n\\) becomes larger and \\(p\\) smaller, while their product \\(np\\) (representing the average number of successes) remains constant, the Binomial distribution approaches the Poisson distribution. This constant product, \\(np\\), is what we denote as \\(\\lambda\\) in the Poisson distribution.\n\n\n\nThe formula for the Poisson distribution is as follows: \\[ P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} \\] In this equation, \\(X\\) is the random variable representing the number of successes, \\(k\\) is the specific number of successes we are interested in, \\(\\lambda\\) is the average rate of success, \\(e\\) is the base of the natural logarithm, and \\(k!\\) is the factorial of \\(k\\).\n\n\n\nTo further our understanding of the transition from the Binomial to the Poisson distribution, visual aids can be immensely helpful. In this section, we will use a series of graphs to illustrate how the Binomial distribution morphs into the Poisson distribution as the number of trials increases and the probability of success decreases.\n\nImporting Libraries First, we install and import the necessary Python libraries for our calculations and visualizations.\n\nimport sys\n!{sys.executable} -m pip install numpy\n!{sys.executable} -m pip install matplotlib\n!{sys.executable} -m pip install scipy\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom, poisson\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: numpy in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (1.26.2)\nWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\nYou should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: matplotlib in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (3.8.2)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.45.1)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: importlib-resources&gt;=3.2.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.1.1)\nRequirement already satisfied: packaging&gt;=20.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (23.2)\nRequirement already satisfied: pillow&gt;=8 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.1.0)\nRequirement already satisfied: numpy&lt;2,&gt;=1.21 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.26.2)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: zipp&gt;=3.1.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from importlib-resources&gt;=3.2.0-&gt;matplotlib) (3.17.0)\nRequirement already satisfied: six&gt;=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.15.0)\nWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\nYou should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: scipy in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (1.11.4)\nRequirement already satisfied: numpy&lt;1.28.0,&gt;=1.21.6 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from scipy) (1.26.2)\nWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\nYou should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\n\n\nSetting Parameters for the Distributions We define a range of \\(n\\) values to show how increasing the number of trials and decreasing the probability of success in each trial impacts the distribution. We also set a constant value for \\(p\\), the probability of success, and choose a value for \\(k\\), the number of successes we‚Äôre interested in.\n\nn_values = [20, 50, 100, 500]  # Increasing number of trials\np_values = [0.9, 0.8, 0.3, 0.01]  # Decreasing number of trials\nk = 5                          # Number of successes\n\nCalculating and Plotting the Distributions For each value of \\(n\\), we calculate the probabilities using both the Binomial and Poisson distributions and plot them for comparison.\n\nplt.figure(figsize=(12, 8))\n\nfor i, n in enumerate(n_values):\n    lambda_ = n * p_values[i]\n    x = np.arange(0, 20)\n    binom_pmf = binom.pmf(x, n, p_values[i])\n    poisson_pmf = poisson.pmf(x, lambda_)\n\n    plt.subplot(2, 2, i+1)\n    plt.plot(x, binom_pmf, 'o-', label=\"Binomial\")\n    plt.plot(x, poisson_pmf, 'x-', label=\"Poisson\")\n    plt.title(f'n = {n}, p = {p_values[i]}, lambda = {lambda_}')\n    plt.xlabel('k (Number of successes)')\n    plt.ylabel('Probability')\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nShifting Shapes: As \\(n\\) increases and \\(p\\) decreases, we observe that the shape of the Binomial distribution starts resembling that of the Poisson distribution. Initially, for smaller values of \\(n\\), the Binomial distribution might appear distinctly different. However, as \\(n\\) grows, the graphs showcase a closer alignment between the two distributions.\nConvergence to Poisson: The convergence of the Binomial distribution to the Poisson distribution is evident in these plots. The Poisson distribution begins to effectively approximate the Binomial distribution, especially as the product \\(np\\) (or \\(\\lambda\\)) remains constant.\nPractical Implications: This visual demonstration is crucial for understanding how the Poisson distribution can be used in real-life scenarios where the Binomial distribution is impractical due to a large number of trials. It highlights the flexibility and applicability of the Poisson distribution in various fields, from telecommunications to natural event modeling.\n\n\n\n\n\nNow that we have a foundational understanding of the Poisson distribution and its relationship with the Binomial distribution, let‚Äôs apply this knowledge to a practical scenario: the number of emails received per hour. This real-world example will illustrate how the Poisson distribution is used to model and understand everyday phenomena.\n\n\nConsider a situation where you‚Äôre monitoring the number of emails received in your office inbox. After some observation, you determine that, on average, you receive 5 emails per hour. In the context of the Poisson distribution, this average rate, 5 emails per hour, is our \\(\\lambda\\) (lambda).\n\n\n\nTo understand how the Poisson distribution works in this scenario, we will calculate the probabilities of receiving exactly 3, 5, or 10 emails in an hour. We‚Äôll use Python to perform these calculations.\n\nDefining the Average Rate (\\(\\lambda\\)) Our average rate \\(\\lambda\\) is 5 emails per hour.\n\nlambda_ = 5  # Average number of emails per hour\n\nCalculating Probabilities We calculate the probability for receiving 3, 5, and 10 emails respectively.\n\nprobs = {}\nfor k in [0, 3, 5, 10, 15]:\n    probs[k] = poisson.pmf(k, lambda_)\n\nInterpreting the Results Let‚Äôs print out the probabilities.\n\nfor k, prob in probs.items():\n    print(f\"Probability of receiving exactly {k} emails: {prob:.4f}\")\n\nProbability of receiving exactly 0 emails: 0.0067\nProbability of receiving exactly 3 emails: 0.1404\nProbability of receiving exactly 5 emails: 0.1755\nProbability of receiving exactly 10 emails: 0.0181\nProbability of receiving exactly 15 emails: 0.0002\n\n\n\n\n\n\nNow, we‚Äôll graph the Poisson distribution for our email scenario to visualize these probabilities.\n\nSetting Up the Plot We will create a plot that shows the probability of receiving a range of emails in an hour.\n\nx = np.arange(0, 15)  # Define the range of emails\ny = poisson.pmf(x, lambda_)\n\nplt.bar(x, y)\nplt.title(\"Poisson Distribution of Emails Received Per Hour\")\nplt.xlabel(\"Number of Emails\")\nplt.ylabel(\"Probability\")\nplt.xticks(x)\nplt.show()\n\n\n\n\n\n\n\n\n\nProbability Results: The calculated probabilities provide insights into the likelihood of different email counts. For instance, if the probability of receiving exactly 10 emails is low, it could indicate an unusually busy hour if it happens.\nGraphical Representation: The bar graph visually demonstrates the probabilities of different email counts per hour, emphasizing the most likely outcomes and showcasing the typical variance one might expect in their inbox.\n\n\n\n\nNext, just for fun, we will calculate and visualize the probability of receiving fewer than a certain number of emails per hour in case you want to know what‚Äôs the possibility of you need to handle less than 0, 3, 5, or 10 emails. For each threshold, we will calculate the cumulative probability of receiving less than that number of emails and visualize these probabilities using bar graphs with highlighted sections.\nThe cumulative probability for receiving fewer than a certain number of emails can be calculated using the cumulative distribution function (CDF) of the Poisson distribution.\n\nDefining the Average Rate (\\(\\lambda\\)) and Thresholds Our average rate, \\(\\lambda\\), is still 5 emails per hour. We also define our thresholds.\n\nlambda_ = 5  # Average number of emails per hour\nthresholds = [0, 3, 5, 10]\n\nCalculating Cumulative Probabilities We calculate the cumulative probability for each threshold.\n\ncdf_values = {}\nfor threshold in thresholds:\n    cdf_values[threshold] = poisson.cdf(threshold, lambda_)\n    print(f\"Probability of receiving less than {threshold} emails in an hour: {cdf_values[threshold]:.4f}\")\n\nProbability of receiving less than 0 emails in an hour: 0.0067\nProbability of receiving less than 3 emails in an hour: 0.2650\nProbability of receiving less than 5 emails in an hour: 0.6160\nProbability of receiving less than 10 emails in an hour: 0.9863\n\n\n\n\n\n\nWe will create a series of bar graphs to visually represent these probabilities. Each graph will highlight the bars representing the number of emails up to the threshold.\n\nSetting Up the Plot We define the range for the number of emails.\n\nx = np.arange(0, 15)  # Define the range of emails\ny = poisson.pmf(x, lambda_)\n\nCreating and Coloring the Graphs We create a separate graph for each threshold, coloring the bars up to that threshold differently.\n\nfor threshold in thresholds:\n    plt.figure(figsize=(6, 4))\n    plt.bar(x, y, color='grey')  # Default color\n    plt.bar(x[:threshold+1], y[:threshold+1], color='#E83283')  # Highlight up to the threshold\n    plt.title(f\"Probability of Receiving Fewer than {threshold} Emails\")\n    plt.xlabel(\"Number of Emails\")\n    plt.ylabel(\"Probability\")\n    plt.xticks(x)\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Cumulative Probabilities: These graphs provide a visual representation of the cumulative probability of receiving fewer than a certain number of emails. A higher highlighted area indicates a greater likelihood of receiving fewer emails than the specified threshold.\nPractical Insights: Such visualizations can help individuals and businesses to anticipate and prepare for varying email volumes, thereby aiding in effective time management and resource allocation.\n\n\n\n\n\nHaving applied the Poisson distribution to the scenario of receiving emails per hour, let‚Äôs delve deeper into how this analysis can be beneficial for businesses or individuals and attempt to compare our theoretical findings with actual data.\n\n\nUnderstanding the pattern of email arrivals using the Poisson distribution can have significant practical applications, particularly in business settings.\n\nWorkload Management: For individuals or teams managing large volumes of emails, understanding the likelihood of receiving a certain number of emails can help in planning their workload. If the probability of receiving a high number of emails at certain hours is more, one can allocate more resources or time to manage this influx.\nStaffing in Customer Service: Customer service departments that rely heavily on email communication can use these predictions to staff their teams more efficiently. During hours predicted to have a higher volume of emails, more staff can be scheduled to ensure timely responses.\nPredictive Analysis for Planning: Businesses can use this data for predictive analysis. If certain days or times are consistently seeing a higher volume of emails, this information can be used for strategic planning, such as launching marketing emails or scheduling maintenance activities.\n\n\n\n\nTo demonstrate the practical application of our theoretical analysis, let‚Äôs compare the Poisson distribution with actual email data. For this example, we‚Äôll assume a sample data set representing the number of emails received per hour over a week.\n\nGenerating Sample Data Let‚Äôs simulate some sample email data for this comparison.\n\nnp.random.seed(0)  # For reproducibility\nsample_data = np.random.poisson(lambda_, size=168)  # Simulating for 7 days (24 hours each)\n\nComparison with Theoretical Distribution We will plot the actual data alongside our theoretical Poisson distribution.\n\nplt.figure(figsize=(10, 5))\nplt.hist(sample_data, bins=range(15), alpha=0.7, label=\"Actual Data\")\nplt.plot(x, y * 168, 'o-', label=\"Theoretical Poisson Distribution\")  # 168 hours in a week\nplt.title(\"Comparison of Actual Email Data with Poisson Distribution\")\nplt.xlabel(\"Number of Emails\")\nplt.ylabel(\"Frequency\")\nplt.xticks(range(15))\nplt.legend()\nplt.show()\n\n\n\n\nIn the histogram generated above, the y-axis, labeled ‚ÄúFrequency,‚Äù represents the number of hours during the week when a specific number of emails were received.\nEach bar in the histogram corresponds to a particular number of emails received per hour (shown on the x-axis). The height of each bar indicates how many hours in the simulated week had that exact count of emails.\nFor example, if one of the bars represents 4 emails and its height reaches up to 10 on the y-axis, this means that there were 10 hours in the simulated week during which exactly 4 emails were received. The y-axis in this context is a count of the number of occurrences of each email count per hour across the entire week.\nTo calculate and plot the theoretical poisson distribution, x is an array representing different possible email counts per hour. y is calculated using the Poisson probability mass function (pmf) for each count in x, given the average rate lambda_. This y represents the theoretical probability of each email count per hour according to the Poisson distribution. The values in y are then multiplied by 168 (the total number of hours in the week) to scale these probabilities to the same total time frame as the actual data. The result is plotted as a line plot with markers (‚Äòo-‚Äô) overlaid on the histogram. This line represents the expected frequency of each email count per hour over a week according to the Poisson distribution.\n\n\n\n\n\nAlignment with Theoretical Model: If the actual data closely aligns with the theoretical Poisson distribution, it validates the use of this model for predicting email patterns.\nIdentifying Anomalies: Any significant deviations from the theoretical distribution might indicate anomalies or special events, prompting further investigation.\nReal-World Relevance: This comparison underscores the relevance of the Poisson distribution in modeling real-world scenarios, providing a valuable tool for data-driven decision-making.\n\n\n\n\n\nThroughout this exploration, we‚Äôve seen how the Poisson distribution serves as a powerful statistical tool for understanding and predicting patterns in events that occur rarely but with regularity. Using the example of the number of emails received per hour, we‚Äôve illustrated not only the theoretical underpinnings of the Poisson distribution but also its practical applications in real-world scenarios.\nThe transition from the Binomial to the Poisson distribution, highlighted through graphical representations, demonstrates the versatility and efficiency of the Poisson distribution in situations involving large numbers of trials and low probabilities of success. The example of email patterns particularly resonates as it‚Äôs a common experience in both personal and professional settings. By applying the Poisson distribution to this scenario, we‚Äôve shown how it can be used to predict the frequency of events over a given time frame, providing valuable insights for planning and decision-making.\nIn professional contexts, especially in fields like customer service, IT, and communications, the Poisson distribution can be a vital tool for workload management and resource allocation. It allows businesses to predict and prepare for fluctuating demands, ensuring efficiency and responsiveness. Similarly, in personal contexts, understanding such patterns can help individuals manage their time and expectations more effectively.\nThis journey through the realms of probability and statistics underscores the importance of statistical tools like the Poisson distribution. They are not just abstract mathematical concepts but practical instruments that can be employed to make sense of the world around us, understand patterns, and make informed decisions. As we have seen, even something as commonplace as the flow of emails can be modeled and understood through the lens of statistics, revealing the hidden rhythms and patterns of our daily lives.\nIn conclusion, the Poisson distribution is more than just a statistical formula; it‚Äôs a lens through which we can view and interpret the regular yet random events of our world, making it an indispensable tool in both our personal and professional toolkits."
  },
  {
    "objectID": "posts/probability/index.html#introduction",
    "href": "posts/probability/index.html#introduction",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "In the realm of probability and statistics, the Poisson distribution is a fundamental concept, often used to model the frequency of various types of events. This blog post aims to demystify the Poisson distribution by tracing its roots back to the Binomial distribution, and then, applying it to a real-world scenario: analyzing the number of emails received per hour."
  },
  {
    "objectID": "posts/probability/index.html#the-theoretical-underpinnings",
    "href": "posts/probability/index.html#the-theoretical-underpinnings",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "The journey begins with the Binomial distribution, which calculates the probability of obtaining a certain number of successes in a fixed number of independent trials. It‚Äôs expressed as:\n[ P(X = k) = p^k (1-p)^{n-k} ]\nwhere: - ( n ) is the number of trials - ( k ) is the number of successes - ( p ) is the probability of success on a single trial.\n\n\n\nThe Poisson distribution emerges as a special case of the Binomial distribution, particularly when the number of trials is large (( n )), and the probability of success is small (( p )), while their product (( = np )) remains constant.\nThe Poisson distribution is given by:\n[ P(X = k) = ]\nwhere ( ) is the mean number of successes over the interval.\n\n\n\nBy graphically comparing the two distributions for varying values of ( n ) and ( p ), we can observe how the Binomial distribution converges to the Poisson distribution under these conditions."
  },
  {
    "objectID": "posts/probability/index.html#practical-application-email-analysis",
    "href": "posts/probability/index.html#practical-application-email-analysis",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "Now, let‚Äôs apply this knowledge to a practical scenario: estimating the number of emails one might receive in an hour.\n\n\nFor this experiment, we assume an average of 5 emails per hour. This rate (( )) serves as our parameter for the Poisson distribution.\n\n\n\nUsing a programming tool like Python, we can simulate the receipt of emails over a 24-hour period. The Poisson distribution will allow us to model the probability of receiving a certain number of emails each hour.\n\n\n\nThe simulation results can be visualized in a histogram, showing the frequency of hours with a specific number of emails. This graph provides a clear picture of the email distribution pattern over the course of a day."
  },
  {
    "objectID": "posts/probability/index.html#conclusion-insights-and-applications",
    "href": "posts/probability/index.html#conclusion-insights-and-applications",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "This analysis not only deepens our understanding of the Poisson distribution but also demonstrates its practical utility in everyday scenarios. Whether it‚Äôs for planning resources in customer service or managing workload in IT support, the Poisson distribution offers valuable insights into event frequencies.\nUnderstanding statistical concepts like the Poisson distribution and their derivation from more fundamental principles enriches our ability to interpret and analyze the world around us. Stay tuned for more explorations into the exciting world of probability and statistics!"
  },
  {
    "objectID": "posts/probability/index.html#understanding-the-binomial-distribution",
    "href": "posts/probability/index.html#understanding-the-binomial-distribution",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "The Binomial distribution is a cornerstone of probability theory, serving as a foundation for more complex distributions, including the Poisson distribution. This section aims to clarify the basics of the Binomial distribution.\n\n\nThe Binomial distribution is a probability distribution that models the number of successes in a fixed number of independent trials, with each trial having the same probability of success. It is particularly useful in scenarios with two possible outcomes, often labeled as ‚Äúsuccess‚Äù and ‚Äúfailure.‚Äù\n\n\n\n\nNumber of Trials (\\(n\\)): This denotes the total number of independent trials or experiments.\nProbability of Success (\\(p\\)): The probability of achieving a successful outcome in an individual trial.\nNumber of Successes (\\(k\\)): The specific count of successful outcomes we are interested in.\n\n\n\n\nThe probability of observing exactly \\(k\\) successes in \\(n\\) trials is described by the Binomial formula: \\[ P(X = k) = \\binom{n}{k} p^k (1 - p)^{n - k} \\] Here, \\(\\binom{n}{k}\\) (pronounced ‚Äún choose k‚Äù) represents the number of ways to select \\(k\\) successes from \\(n\\) trials.\n\n\n\nConsider a scenario where you flip a coin 10 times. What is the probability of flipping exactly 4 heads? In this example: - \\(n = 10\\) (the total number of coin flips), - \\(p = 0.5\\) (the probability of flipping heads on any single coin flip), - \\(k = 4\\) (the number of heads we are trying to achieve).\nUsing the Binomial formula, the probability is: \\[ P(X = 4) = \\binom{10}{4} (0.5)^4 (1 - 0.5)^{10 - 4} \\]\n\n\n\nThe Binomial distribution is crucial in understanding binary outcomes across various fields such as psychology, medicine, and quality control. It provides a framework for scenarios with fixed trial numbers and clear success/failure outcomes. However, for large-scale or continuous-event contexts, the Poisson distribution becomes more relevant, as we will explore in subsequent sections."
  },
  {
    "objectID": "posts/probability/index.html#transitioning-to-the-poisson-distribution",
    "href": "posts/probability/index.html#transitioning-to-the-poisson-distribution",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "In this section, we explore the intriguing relationship between the Binomial and Poisson distributions and how one transitions into the other under certain conditions. This transition is particularly important in scenarios involving a large number of trials and a small probability of success.\n\n\nThe Binomial distribution effectively models situations with a fixed number of independent trials and a constant probability of success in each trial. However, when we consider scenarios where the number of trials (\\(n\\)) is very large, and the probability of success in each trial (\\(p\\)) is very small, the Binomial distribution becomes less practical for calculations. This is where the Poisson distribution becomes relevant.\nThe key to this transition lies in the product of \\(n\\) and \\(p\\). As \\(n\\) becomes larger and \\(p\\) smaller, while their product \\(np\\) (representing the average number of successes) remains constant, the Binomial distribution approaches the Poisson distribution. This constant product, \\(np\\), is what we denote as \\(\\lambda\\) in the Poisson distribution.\n\n\n\nThe formula for the Poisson distribution is as follows: \\[ P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} \\] In this equation, \\(X\\) is the random variable representing the number of successes, \\(k\\) is the specific number of successes we are interested in, \\(\\lambda\\) is the average rate of success, \\(e\\) is the base of the natural logarithm, and \\(k!\\) is the factorial of \\(k\\).\n\n\n\nTo further our understanding of the transition from the Binomial to the Poisson distribution, visual aids can be immensely helpful. In this section, we will use a series of graphs to illustrate how the Binomial distribution morphs into the Poisson distribution as the number of trials increases and the probability of success decreases.\n\nImporting Libraries First, we install and import the necessary Python libraries for our calculations and visualizations.\n\nimport sys\n!{sys.executable} -m pip install numpy\n!{sys.executable} -m pip install matplotlib\n!{sys.executable} -m pip install scipy\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom, poisson\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: numpy in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (1.26.2)\nWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\nYou should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: matplotlib in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (3.8.2)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.45.1)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: importlib-resources&gt;=3.2.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.1.1)\nRequirement already satisfied: packaging&gt;=20.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (23.2)\nRequirement already satisfied: pillow&gt;=8 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.1.0)\nRequirement already satisfied: numpy&lt;2,&gt;=1.21 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.26.2)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: zipp&gt;=3.1.0 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from importlib-resources&gt;=3.2.0-&gt;matplotlib) (3.17.0)\nRequirement already satisfied: six&gt;=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.15.0)\nWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\nYou should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: scipy in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (1.11.4)\nRequirement already satisfied: numpy&lt;1.28.0,&gt;=1.21.6 in /Users/zimingfang/Library/Python/3.9/lib/python/site-packages (from scipy) (1.26.2)\nWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\nYou should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\n\n\nSetting Parameters for the Distributions We define a range of \\(n\\) values to show how increasing the number of trials and decreasing the probability of success in each trial impacts the distribution. We also set a constant value for \\(p\\), the probability of success, and choose a value for \\(k\\), the number of successes we‚Äôre interested in.\n\nn_values = [20, 50, 100, 500]  # Increasing number of trials\np_values = [0.9, 0.8, 0.3, 0.01]  # Decreasing number of trials\nk = 5                          # Number of successes\n\nCalculating and Plotting the Distributions For each value of \\(n\\), we calculate the probabilities using both the Binomial and Poisson distributions and plot them for comparison.\n\nplt.figure(figsize=(12, 8))\n\nfor i, n in enumerate(n_values):\n    lambda_ = n * p_values[i]\n    x = np.arange(0, 20)\n    binom_pmf = binom.pmf(x, n, p_values[i])\n    poisson_pmf = poisson.pmf(x, lambda_)\n\n    plt.subplot(2, 2, i+1)\n    plt.plot(x, binom_pmf, 'o-', label=\"Binomial\")\n    plt.plot(x, poisson_pmf, 'x-', label=\"Poisson\")\n    plt.title(f'n = {n}, p = {p_values[i]}, lambda = {lambda_}')\n    plt.xlabel('k (Number of successes)')\n    plt.ylabel('Probability')\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nShifting Shapes: As \\(n\\) increases and \\(p\\) decreases, we observe that the shape of the Binomial distribution starts resembling that of the Poisson distribution. Initially, for smaller values of \\(n\\), the Binomial distribution might appear distinctly different. However, as \\(n\\) grows, the graphs showcase a closer alignment between the two distributions.\nConvergence to Poisson: The convergence of the Binomial distribution to the Poisson distribution is evident in these plots. The Poisson distribution begins to effectively approximate the Binomial distribution, especially as the product \\(np\\) (or \\(\\lambda\\)) remains constant.\nPractical Implications: This visual demonstration is crucial for understanding how the Poisson distribution can be used in real-life scenarios where the Binomial distribution is impractical due to a large number of trials. It highlights the flexibility and applicability of the Poisson distribution in various fields, from telecommunications to natural event modeling."
  },
  {
    "objectID": "posts/probability/index.html#visualizing-the-transition-through-graphs",
    "href": "posts/probability/index.html#visualizing-the-transition-through-graphs",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "To further our understanding of the transition from the Binomial to the Poisson distribution, visual aids can be immensely helpful. In this section, we will use a series of graphs to illustrate how the Binomial distribution morphs into the Poisson distribution as the number of trials increases and the probability of success decreases.\n\n\nWe will generate graphs using Python and Jupyter Notebook. Our objective is to visualize the Binomial distribution for various values of \\(n\\) (number of trials) and a decreasing \\(p\\) (probability of success), and compare these graphs to the corresponding Poisson distribution.\n\nSetting Up the Python Environment We begin by importing the necessary libraries for our calculations and visualizations.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom, poisson\n\nDefining Parameters for the Distributions We choose a range of \\(n\\) values to demonstrate the effect of increasing trials. We maintain a small probability of success \\(p\\).\n\nn_values = [20, 50, 100, 500]  # Increasing number of trials\np = 0.1                        # Probability of success\n\nCalculating and Plotting the Distributions For each \\(n\\), we compute and plot both the Binomial and Poisson probabilities.\n\nplt.figure(figsize=(12, 8))\n\nfor i, n in enumerate(n_values):\n    lambda_ = n * p\n    x = np.arange(0, 20)\n    binom_pmf = binom.pmf(x, n, p)\n    poisson_pmf = poisson.pmf(x, lambda_)\n\n    plt.subplot(2, 2, i+1)\n    plt.plot(x, binom_pmf, 'o-', label=\"Binomial\")\n    plt.plot(x, poisson_pmf, 'x-', label=\"Poisson\")\n    plt.title(f'n = {n}, p = {p}, lambda = {lambda_}')\n    plt.xlabel('k (Number of successes)')\n    plt.ylabel('Probability')\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nShifting Shapes: As \\(n\\) increases and \\(p\\) decreases, we observe that the shape of the Binomial distribution starts resembling that of the Poisson distribution. Initially, for smaller values of \\(n\\), the Binomial distribution might appear distinctly different. However, as \\(n\\) grows, the graphs showcase a closer alignment between the two distributions.\nConvergence to Poisson: The convergence of the Binomial distribution to the Poisson distribution is evident in these plots. The Poisson distribution begins to effectively approximate the Binomial distribution, especially as the product \\(np\\) (or \\(\\lambda\\)) remains constant.\nPractical Implications: This visual demonstration is crucial for understanding how the Poisson distribution can be used in real-life scenarios where the Binomial distribution is impractical due to a large number of trials. It highlights the flexibility and applicability of the Poisson distribution in various fields, from telecommunications to natural event modeling."
  },
  {
    "objectID": "posts/probability/index.html#real-world-application---emails-per-hour",
    "href": "posts/probability/index.html#real-world-application---emails-per-hour",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "Now that we have a foundational understanding of the Poisson distribution and its relationship with the Binomial distribution, let‚Äôs apply this knowledge to a practical scenario: the number of emails received per hour. This real-world example will illustrate how the Poisson distribution is used to model and understand everyday phenomena.\n\n\nConsider a situation where you‚Äôre monitoring the number of emails received in your office inbox. After some observation, you determine that, on average, you receive 5 emails per hour. In the context of the Poisson distribution, this average rate, 5 emails per hour, is our \\(\\lambda\\) (lambda).\n\n\n\nTo understand how the Poisson distribution works in this scenario, we will calculate the probabilities of receiving exactly 3, 5, or 10 emails in an hour. We‚Äôll use Python to perform these calculations.\n\nDefining the Average Rate (\\(\\lambda\\)) Our average rate \\(\\lambda\\) is 5 emails per hour.\n\nlambda_ = 5  # Average number of emails per hour\n\nCalculating Probabilities We calculate the probability for receiving 3, 5, and 10 emails respectively.\n\nprobs = {}\nfor k in [0, 3, 5, 10, 15]:\n    probs[k] = poisson.pmf(k, lambda_)\n\nInterpreting the Results Let‚Äôs print out the probabilities.\n\nfor k, prob in probs.items():\n    print(f\"Probability of receiving exactly {k} emails: {prob:.4f}\")\n\nProbability of receiving exactly 0 emails: 0.0067\nProbability of receiving exactly 3 emails: 0.1404\nProbability of receiving exactly 5 emails: 0.1755\nProbability of receiving exactly 10 emails: 0.0181\nProbability of receiving exactly 15 emails: 0.0002\n\n\n\n\n\n\nNow, we‚Äôll graph the Poisson distribution for our email scenario to visualize these probabilities.\n\nSetting Up the Plot We will create a plot that shows the probability of receiving a range of emails in an hour.\n\nx = np.arange(0, 15)  # Define the range of emails\ny = poisson.pmf(x, lambda_)\n\nplt.bar(x, y)\nplt.title(\"Poisson Distribution of Emails Received Per Hour\")\nplt.xlabel(\"Number of Emails\")\nplt.ylabel(\"Probability\")\nplt.xticks(x)\nplt.show()\n\n\n\n\n\n\n\n\n\nProbability Results: The calculated probabilities provide insights into the likelihood of different email counts. For instance, if the probability of receiving exactly 10 emails is low, it could indicate an unusually busy hour if it happens.\nGraphical Representation: The bar graph visually demonstrates the probabilities of different email counts per hour, emphasizing the most likely outcomes and showcasing the typical variance one might expect in their inbox.\n\n\n\n\nNext, just for fun, we will calculate and visualize the probability of receiving fewer than a certain number of emails per hour in case you want to know what‚Äôs the possibility of you need to handle less than 0, 3, 5, or 10 emails. For each threshold, we will calculate the cumulative probability of receiving less than that number of emails and visualize these probabilities using bar graphs with highlighted sections.\nThe cumulative probability for receiving fewer than a certain number of emails can be calculated using the cumulative distribution function (CDF) of the Poisson distribution.\n\nDefining the Average Rate (\\(\\lambda\\)) and Thresholds Our average rate, \\(\\lambda\\), is still 5 emails per hour. We also define our thresholds.\n\nlambda_ = 5  # Average number of emails per hour\nthresholds = [0, 3, 5, 10]\n\nCalculating Cumulative Probabilities We calculate the cumulative probability for each threshold.\n\ncdf_values = {}\nfor threshold in thresholds:\n    cdf_values[threshold] = poisson.cdf(threshold, lambda_)\n    print(f\"Probability of receiving less than {threshold} emails in an hour: {cdf_values[threshold]:.4f}\")\n\nProbability of receiving less than 0 emails in an hour: 0.0067\nProbability of receiving less than 3 emails in an hour: 0.2650\nProbability of receiving less than 5 emails in an hour: 0.6160\nProbability of receiving less than 10 emails in an hour: 0.9863\n\n\n\n\n\n\nWe will create a series of bar graphs to visually represent these probabilities. Each graph will highlight the bars representing the number of emails up to the threshold.\n\nSetting Up the Plot We define the range for the number of emails.\n\nx = np.arange(0, 15)  # Define the range of emails\ny = poisson.pmf(x, lambda_)\n\nCreating and Coloring the Graphs We create a separate graph for each threshold, coloring the bars up to that threshold differently.\n\nfor threshold in thresholds:\n    plt.figure(figsize=(6, 4))\n    plt.bar(x, y, color='grey')  # Default color\n    plt.bar(x[:threshold+1], y[:threshold+1], color='#E83283')  # Highlight up to the threshold\n    plt.title(f\"Probability of Receiving Fewer than {threshold} Emails\")\n    plt.xlabel(\"Number of Emails\")\n    plt.ylabel(\"Probability\")\n    plt.xticks(x)\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Cumulative Probabilities: These graphs provide a visual representation of the cumulative probability of receiving fewer than a certain number of emails. A higher highlighted area indicates a greater likelihood of receiving fewer emails than the specified threshold.\nPractical Insights: Such visualizations can help individuals and businesses to anticipate and prepare for varying email volumes, thereby aiding in effective time management and resource allocation."
  },
  {
    "objectID": "posts/probability/index.html#deep-dive-into-the-email-example",
    "href": "posts/probability/index.html#deep-dive-into-the-email-example",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "Having applied the Poisson distribution to the scenario of receiving emails per hour, let‚Äôs delve deeper into how this analysis can be beneficial for businesses or individuals and attempt to compare our theoretical findings with actual data.\n\n\nUnderstanding the pattern of email arrivals using the Poisson distribution can have significant practical applications, particularly in business settings.\n\nWorkload Management: For individuals or teams managing large volumes of emails, understanding the likelihood of receiving a certain number of emails can help in planning their workload. If the probability of receiving a high number of emails at certain hours is more, one can allocate more resources or time to manage this influx.\nStaffing in Customer Service: Customer service departments that rely heavily on email communication can use these predictions to staff their teams more efficiently. During hours predicted to have a higher volume of emails, more staff can be scheduled to ensure timely responses.\nPredictive Analysis for Planning: Businesses can use this data for predictive analysis. If certain days or times are consistently seeing a higher volume of emails, this information can be used for strategic planning, such as launching marketing emails or scheduling maintenance activities.\n\n\n\n\nTo demonstrate the practical application of our theoretical analysis, let‚Äôs compare the Poisson distribution with actual email data. For this example, we‚Äôll assume a sample data set representing the number of emails received per hour over a week.\n\nGenerating Sample Data Let‚Äôs simulate some sample email data for this comparison.\n\nnp.random.seed(0)  # For reproducibility\nsample_data = np.random.poisson(lambda_, size=168)  # Simulating for 7 days (24 hours each)\n\nComparison with Theoretical Distribution We will plot the actual data alongside our theoretical Poisson distribution.\n\nplt.figure(figsize=(10, 5))\nplt.hist(sample_data, bins=range(15), alpha=0.7, label=\"Actual Data\")\nplt.plot(x, y * 168, 'o-', label=\"Theoretical Poisson Distribution\")  # 168 hours in a week\nplt.title(\"Comparison of Actual Email Data with Poisson Distribution\")\nplt.xlabel(\"Number of Emails\")\nplt.ylabel(\"Frequency\")\nplt.xticks(range(15))\nplt.legend()\nplt.show()\n\n\n\n\nIn the histogram generated above, the y-axis, labeled ‚ÄúFrequency,‚Äù represents the number of hours during the week when a specific number of emails were received.\nEach bar in the histogram corresponds to a particular number of emails received per hour (shown on the x-axis). The height of each bar indicates how many hours in the simulated week had that exact count of emails.\nFor example, if one of the bars represents 4 emails and its height reaches up to 10 on the y-axis, this means that there were 10 hours in the simulated week during which exactly 4 emails were received. The y-axis in this context is a count of the number of occurrences of each email count per hour across the entire week.\nTo calculate and plot the theoretical poisson distribution, x is an array representing different possible email counts per hour. y is calculated using the Poisson probability mass function (pmf) for each count in x, given the average rate lambda_. This y represents the theoretical probability of each email count per hour according to the Poisson distribution. The values in y are then multiplied by 168 (the total number of hours in the week) to scale these probabilities to the same total time frame as the actual data. The result is plotted as a line plot with markers (‚Äòo-‚Äô) overlaid on the histogram. This line represents the expected frequency of each email count per hour over a week according to the Poisson distribution.\n\n\n\n\n\nAlignment with Theoretical Model: If the actual data closely aligns with the theoretical Poisson distribution, it validates the use of this model for predicting email patterns.\nIdentifying Anomalies: Any significant deviations from the theoretical distribution might indicate anomalies or special events, prompting further investigation.\nReal-World Relevance: This comparison underscores the relevance of the Poisson distribution in modeling real-world scenarios, providing a valuable tool for data-driven decision-making."
  },
  {
    "objectID": "posts/probability/index.html#conclusion",
    "href": "posts/probability/index.html#conclusion",
    "title": "Probability Theory and Random Variables",
    "section": "",
    "text": "Throughout this exploration, we‚Äôve seen how the Poisson distribution serves as a powerful statistical tool for understanding and predicting patterns in events that occur rarely but with regularity. Using the example of the number of emails received per hour, we‚Äôve illustrated not only the theoretical underpinnings of the Poisson distribution but also its practical applications in real-world scenarios.\nThe transition from the Binomial to the Poisson distribution, highlighted through graphical representations, demonstrates the versatility and efficiency of the Poisson distribution in situations involving large numbers of trials and low probabilities of success. The example of email patterns particularly resonates as it‚Äôs a common experience in both personal and professional settings. By applying the Poisson distribution to this scenario, we‚Äôve shown how it can be used to predict the frequency of events over a given time frame, providing valuable insights for planning and decision-making.\nIn professional contexts, especially in fields like customer service, IT, and communications, the Poisson distribution can be a vital tool for workload management and resource allocation. It allows businesses to predict and prepare for fluctuating demands, ensuring efficiency and responsiveness. Similarly, in personal contexts, understanding such patterns can help individuals manage their time and expectations more effectively.\nThis journey through the realms of probability and statistics underscores the importance of statistical tools like the Poisson distribution. They are not just abstract mathematical concepts but practical instruments that can be employed to make sense of the world around us, understand patterns, and make informed decisions. As we have seen, even something as commonplace as the flow of emails can be modeled and understood through the lens of statistics, revealing the hidden rhythms and patterns of our daily lives.\nIn conclusion, the Poisson distribution is more than just a statistical formula; it‚Äôs a lens through which we can view and interpret the regular yet random events of our world, making it an indispensable tool in both our personal and professional toolkits."
  }
]