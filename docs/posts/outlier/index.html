<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Joanna Fang">
<meta name="dcterms.date" content="2023-12-06">

<title>Ziming’s Journey in Machine Learning - Anomaly/Outlier Detection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Ziming’s Journey in Machine Learning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/joannafg/cs5805-2" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/joanna-fang-6122ba182/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Anomaly/Outlier Detection</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i></button></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">ml</div>
                <div class="quarto-category">code</div>
                <div class="quarto-category">linear regression</div>
                <div class="quarto-category">nonlinear regression</div>
                <div class="quarto-category">pollution</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Joanna Fang </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 6, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#detecting-anomalies-in-air-pollution-data-a-data-science-project" id="toc-detecting-anomalies-in-air-pollution-data-a-data-science-project" class="nav-link active" data-scroll-target="#detecting-anomalies-in-air-pollution-data-a-data-science-project">Detecting Anomalies in Air Pollution Data: A Data Science Project</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#data-exploration-and-preprocessing" id="toc-data-exploration-and-preprocessing" class="nav-link" data-scroll-target="#data-exploration-and-preprocessing">Data Exploration and Preprocessing</a></li>
  </ul></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/joannafg/cs5805-2/edit/main/posts/outlier/index.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/joannafg/cs5805-2/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="detecting-anomalies-in-air-pollution-data-a-data-science-project" class="level1">
<h1>Detecting Anomalies in Air Pollution Data: A Data Science Project</h1>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="thumbnail.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
</figure>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to our exploration of “Detecting Anomalies in Air Pollution Data,” a vital project in the realm of environmental monitoring. With increasing concerns about air quality and its impact on public health and the environment, identifying irregularities in air pollution data has never been more critical.</p>
<p>This project leverages a comprehensive dataset from the Beijing Multi-site Air Quality Data, which offers a rich tapestry of air pollutant measurements and meteorological data across various sites in Beijing. The data spans from 2013 to 2017, providing insights into pollutants like PM2.5, PM10, SO2, NO2, and CO, as well as meteorological conditions like temperature, humidity, and wind speed.</p>
<p>Our primary goal is to detect unusual patterns or outliers in air quality data that might signify environmental hazards, technical errors in data collection, or significant meteorological impacts. By accomplishing this, we aim to contribute to more effective environmental monitoring and policy-making.</p>
<section id="data-exploration-and-preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="data-exploration-and-preprocessing">Data Exploration and Preprocessing</h3>
<section id="understanding-the-dataset" class="level4">
<h4 class="anchored" data-anchor-id="understanding-the-dataset">Understanding the Dataset</h4>
<p>The first step in our data science journey involves getting acquainted with the dataset’s structure and characteristics. This involves examining the various columns of the dataset, which include both pollutant levels and meteorological factors.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>sample_data <span class="op">=</span> pd.read_csv(<span class="st">'air_data_all.csv'</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>sample_data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">No</th>
<th data-quarto-table-cell-role="th">year</th>
<th data-quarto-table-cell-role="th">month</th>
<th data-quarto-table-cell-role="th">day</th>
<th data-quarto-table-cell-role="th">hour</th>
<th data-quarto-table-cell-role="th">PM2.5</th>
<th data-quarto-table-cell-role="th">PM10</th>
<th data-quarto-table-cell-role="th">SO2</th>
<th data-quarto-table-cell-role="th">NO2</th>
<th data-quarto-table-cell-role="th">CO</th>
<th data-quarto-table-cell-role="th">O3</th>
<th data-quarto-table-cell-role="th">TEMP</th>
<th data-quarto-table-cell-role="th">PRES</th>
<th data-quarto-table-cell-role="th">DEWP</th>
<th data-quarto-table-cell-role="th">RAIN</th>
<th data-quarto-table-cell-role="th">wd</th>
<th data-quarto-table-cell-role="th">WSPM</th>
<th data-quarto-table-cell-role="th">station</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>2013</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>6.0</td>
<td>18.0</td>
<td>5.0</td>
<td>NaN</td>
<td>800.0</td>
<td>88.0</td>
<td>0.1</td>
<td>1021.1</td>
<td>-18.6</td>
<td>0.0</td>
<td>NW</td>
<td>4.4</td>
<td>Gucheng</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>2013</td>
<td>3</td>
<td>1</td>
<td>1</td>
<td>6.0</td>
<td>15.0</td>
<td>5.0</td>
<td>NaN</td>
<td>800.0</td>
<td>88.0</td>
<td>-0.3</td>
<td>1021.5</td>
<td>-19.0</td>
<td>0.0</td>
<td>NW</td>
<td>4.0</td>
<td>Gucheng</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>2013</td>
<td>3</td>
<td>1</td>
<td>2</td>
<td>5.0</td>
<td>18.0</td>
<td>NaN</td>
<td>NaN</td>
<td>700.0</td>
<td>52.0</td>
<td>-0.7</td>
<td>1021.5</td>
<td>-19.8</td>
<td>0.0</td>
<td>WNW</td>
<td>4.6</td>
<td>Gucheng</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>2013</td>
<td>3</td>
<td>1</td>
<td>3</td>
<td>6.0</td>
<td>20.0</td>
<td>6.0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>-1.0</td>
<td>1022.7</td>
<td>-21.2</td>
<td>0.0</td>
<td>W</td>
<td>2.8</td>
<td>Gucheng</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>2013</td>
<td>3</td>
<td>1</td>
<td>4</td>
<td>5.0</td>
<td>17.0</td>
<td>5.0</td>
<td>NaN</td>
<td>600.0</td>
<td>73.0</td>
<td>-1.3</td>
<td>1023.0</td>
<td>-21.4</td>
<td>0.0</td>
<td>WNW</td>
<td>3.6</td>
<td>Gucheng</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>By running this code, we get a glimpse of the first few rows of our dataset, allowing us to understand the types of data we will be working with.</p>
</section>
<section id="handling-missing-data-and-categorical-variables" class="level4">
<h4 class="anchored" data-anchor-id="handling-missing-data-and-categorical-variables">Handling Missing Data and Categorical Variables</h4>
<p>Dealing with missing data and categorical variables is a crucial part of data preprocessing. To address this, we first identify the missing values and then decide on an appropriate strategy, such as imputation or removal.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>missing_values <span class="op">=</span> sample_data.isnull().<span class="bu">sum</span>()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>missing_values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>No             0
year           0
month          0
day            0
hour           0
PM2.5       8739
PM10        6449
SO2         9021
NO2        12116
CO         20701
O3         13277
TEMP         398
PRES         393
DEWP         403
RAIN         390
wd          1822
WSPM         318
station        0
dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, OneHotEncoder</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove rows with missing values</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>sample_data <span class="op">=</span> sample_data.dropna()</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify numerical columns</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>numerical_cols <span class="op">=</span> sample_data.select_dtypes(include<span class="op">=</span>[<span class="st">'int64'</span>, <span class="st">'float64'</span>]).columns</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a pipeline for imputing missing values and scaling</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'imputer'</span>, SimpleImputer(strategy<span class="op">=</span><span class="st">'mean'</span>)),  <span class="co"># Replace missing values with mean</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'scaler'</span>, StandardScaler()),                <span class="co"># Scale the data</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the pipeline to the numerical columns</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>scaled_data <span class="op">=</span> pipeline.fit_transform(sample_data[numerical_cols])</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="fl">0.95</span>)  <span class="co"># Retain 95% of the variance</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>principal_components <span class="op">=</span> pca.fit_transform(scaled_data)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify non-numeric (categorical) columns</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>categorical_cols <span class="op">=</span> sample_data.select_dtypes(include<span class="op">=</span>[<span class="st">'object'</span>]).columns</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encode the categorical data</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OneHotEncoder(sparse<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>categorical_encoded <span class="op">=</span> encoder.fit_transform(sample_data[categorical_cols])</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for 'get_feature_names_out' method for naming columns</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">hasattr</span>(encoder, <span class="st">'get_feature_names_out'</span>):</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    encoded_columns <span class="op">=</span> pd.DataFrame(categorical_encoded, columns<span class="op">=</span>encoder.get_feature_names_out(categorical_cols))</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fallback: manually create feature names</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    encoded_columns <span class="op">=</span> pd.DataFrame(categorical_encoded)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    encoded_columns.columns <span class="op">=</span> [col <span class="op">+</span> <span class="st">'_'</span> <span class="op">+</span> <span class="bu">str</span>(i) <span class="cf">for</span> col <span class="kw">in</span> categorical_cols <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(encoded_columns.shape[<span class="dv">1</span>])]</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Concatenate the encoded columns with the original dataset and drop the original categorical columns</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>sample_data_encoded <span class="op">=</span> pd.concat([sample_data.drop(categorical_cols, axis<span class="op">=</span><span class="dv">1</span>), encoded_columns], axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/zimingfang/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(</code></pre>
</div>
</div>
<p>For categorical variables like wind direction, we use encoding techniques to convert them into numerical form, making them suitable for analysis.</p>
</section>
<section id="normalization-and-standardization" class="level4">
<h4 class="anchored" data-anchor-id="normalization-and-standardization">Normalization and Standardization</h4>
<p>Given the varying scales of our numerical features, normalization or standardization becomes necessary. This step ensures that no single feature disproportionately influences the model due to its scale.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>scaled_data <span class="op">=</span> scaler.fit_transform(sample_data[[<span class="st">'PM2.5'</span>, <span class="st">'PM10'</span>, <span class="st">'TEMP'</span>, <span class="st">'PRES'</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="feature-selection-and-engineering" class="level4">
<h4 class="anchored" data-anchor-id="feature-selection-and-engineering">Feature Selection and Engineering</h4>
<p>Finally, we perform feature selection and engineering. This process involves choosing the most relevant features and possibly creating new features to improve our model’s performance.</p>
<ol type="1">
<li><strong>Correlation Analysis</strong>: First, we can perform a correlation analysis to understand the relationships between different features. This helps in identifying features that are strongly correlated with each other, from which we can select the most relevant ones.</li>
</ol>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now perform the correlation analysis on the numerical data</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>corr <span class="op">=</span> sample_data_encoded.corr()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a heatmap</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">".2f"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-6-output-1.png" width="879" height="764"></p>
</div>
</div>
<pre><code>This code generates a heatmap of the correlations between different features. High correlation values suggest a strong relationship, which can inform feature selection.</code></pre>
<ol start="2" type="1">
<li><strong>Principal Component Analysis (PCA)</strong>: PCA is a technique used to reduce the dimensionality of the data, enhancing the interpretability while minimizing information loss.</li>
</ol>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="fl">0.95</span>) <span class="co"># Retain 95% of the variance</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>principal_components <span class="op">=</span> pca.fit_transform(scaled_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>This code applies PCA to the scaled data, reducing the number of features while retaining 95% of the variance in the data.</code></pre>
<ol start="3" type="1">
<li><strong>Feature Engineering</strong>: If applicable, you can create new features that might be more indicative of anomalies. For example, creating a composite air quality index from multiple pollutants.</li>
</ol>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>sample_data[<span class="st">'Air_Quality_Index'</span>] <span class="op">=</span> sample_data[<span class="st">'PM2.5'</span>] <span class="op">*</span> <span class="fl">0.4</span> <span class="op">+</span> sample_data[<span class="st">'PM10'</span>] <span class="op">*</span> <span class="fl">0.2</span> <span class="op">+</span> sample_data[<span class="st">'NO2'</span>] <span class="op">*</span> <span class="fl">0.2</span> <span class="op">+</span> sample_data[<span class="st">'SO2'</span>] <span class="op">*</span> <span class="fl">0.1</span> <span class="op">+</span> sample_data[<span class="st">'CO'</span>] <span class="op">*</span> <span class="fl">0.1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>This code creates a new feature, 'Air_Quality_Index', as a weighted sum of various pollutants, hypothesizing that this composite index might be a more effective predictor of anomalies.</code></pre>
<p>Through these steps, we refine our dataset to include the most relevant features for anomaly detection, enhancing the model’s accuracy and efficiency.</p>


<!-- -->

</section>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb13" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Anomaly/Outlier Detection"</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Joanna Fang"</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2023-12-06"</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [ml, code, linear regression, nonlinear regression, pollution]</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">  html: </span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">    code-block-bg: "#FFFFFF"</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-block-border-left: "#E83283"</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools:</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co">      source: true</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co">      toggle: false</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co">      caption: none</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="fu"># Detecting Anomalies in Air Pollution Data: A Data Science Project</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="al">![](thumbnail.jpg)</span>{width="50%" fig-align="center"}</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>Welcome to our exploration of "Detecting Anomalies in Air Pollution Data," a vital project in the realm of environmental monitoring. With increasing concerns about air quality and its impact on public health and the environment, identifying irregularities in air pollution data has never been more critical.</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>This project leverages a comprehensive dataset from the Beijing Multi-site Air Quality Data, which offers a rich tapestry of air pollutant measurements and meteorological data across various sites in Beijing. The data spans from 2013 to 2017, providing insights into pollutants like PM2.5, PM10, SO2, NO2, and CO, as well as meteorological conditions like temperature, humidity, and wind speed.</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>Our primary goal is to detect unusual patterns or outliers in air quality data that might signify environmental hazards, technical errors in data collection, or significant meteorological impacts. By accomplishing this, we aim to contribute to more effective environmental monitoring and policy-making.</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data Exploration and Preprocessing</span></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a><span class="fu">### Understanding the Dataset</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>The first step in our data science journey involves getting acquainted with the dataset's structure and characteristics. This involves examining the various columns of the dataset, which include both pollutant levels and meteorological factors.</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>sample_data <span class="op">=</span> pd.read_csv(<span class="st">'air_data_all.csv'</span>)</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>sample_data.head()</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>By running this code, we get a glimpse of the first few rows of our dataset, allowing us to understand the types of data we will be working with.</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a><span class="fu">### Handling Missing Data and Categorical Variables</span></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>Dealing with missing data and categorical variables is a crucial part of data preprocessing. To address this, we first identify the missing values and then decide on an appropriate strategy, such as imputation or removal.</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>missing_values <span class="op">=</span> sample_data.isnull().<span class="bu">sum</span>()</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>missing_values</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler, OneHotEncoder</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.impute <span class="im">import</span> SimpleImputer</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove rows with missing values</span></span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>sample_data <span class="op">=</span> sample_data.dropna()</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify numerical columns</span></span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>numerical_cols <span class="op">=</span> sample_data.select_dtypes(include<span class="op">=</span>[<span class="st">'int64'</span>, <span class="st">'float64'</span>]).columns</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a pipeline for imputing missing values and scaling</span></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> Pipeline([</span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'imputer'</span>, SimpleImputer(strategy<span class="op">=</span><span class="st">'mean'</span>)),  <span class="co"># Replace missing values with mean</span></span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>    (<span class="st">'scaler'</span>, StandardScaler()),                <span class="co"># Scale the data</span></span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the pipeline to the numerical columns</span></span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>scaled_data <span class="op">=</span> pipeline.fit_transform(sample_data[numerical_cols])</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply PCA</span></span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="fl">0.95</span>)  <span class="co"># Retain 95% of the variance</span></span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>principal_components <span class="op">=</span> pca.fit_transform(scaled_data)</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify non-numeric (categorical) columns</span></span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>categorical_cols <span class="op">=</span> sample_data.select_dtypes(include<span class="op">=</span>[<span class="st">'object'</span>]).columns</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encode the categorical data</span></span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OneHotEncoder(sparse<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>categorical_encoded <span class="op">=</span> encoder.fit_transform(sample_data[categorical_cols])</span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for 'get_feature_names_out' method for naming columns</span></span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">hasattr</span>(encoder, <span class="st">'get_feature_names_out'</span>):</span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a>    encoded_columns <span class="op">=</span> pd.DataFrame(categorical_encoded, columns<span class="op">=</span>encoder.get_feature_names_out(categorical_cols))</span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fallback: manually create feature names</span></span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a>    encoded_columns <span class="op">=</span> pd.DataFrame(categorical_encoded)</span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a>    encoded_columns.columns <span class="op">=</span> [col <span class="op">+</span> <span class="st">'_'</span> <span class="op">+</span> <span class="bu">str</span>(i) <span class="cf">for</span> col <span class="kw">in</span> categorical_cols <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(encoded_columns.shape[<span class="dv">1</span>])]</span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a><span class="co"># Concatenate the encoded columns with the original dataset and drop the original categorical columns</span></span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a>sample_data_encoded <span class="op">=</span> pd.concat([sample_data.drop(categorical_cols, axis<span class="op">=</span><span class="dv">1</span>), encoded_columns], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-105"><a href="#cb13-105" aria-hidden="true" tabindex="-1"></a>For categorical variables like wind direction, we use encoding techniques to convert them into numerical form, making them suitable for analysis.</span>
<span id="cb13-106"><a href="#cb13-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-107"><a href="#cb13-107" aria-hidden="true" tabindex="-1"></a><span class="fu">### Normalization and Standardization</span></span>
<span id="cb13-108"><a href="#cb13-108" aria-hidden="true" tabindex="-1"></a>Given the varying scales of our numerical features, normalization or standardization becomes necessary. This step ensures that no single feature disproportionately influences the model due to its scale.</span>
<span id="cb13-109"><a href="#cb13-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-112"><a href="#cb13-112" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-113"><a href="#cb13-113" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb13-114"><a href="#cb13-114" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb13-115"><a href="#cb13-115" aria-hidden="true" tabindex="-1"></a>scaled_data <span class="op">=</span> scaler.fit_transform(sample_data[[<span class="st">'PM2.5'</span>, <span class="st">'PM10'</span>, <span class="st">'TEMP'</span>, <span class="st">'PRES'</span>]])</span>
<span id="cb13-116"><a href="#cb13-116" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-117"><a href="#cb13-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-118"><a href="#cb13-118" aria-hidden="true" tabindex="-1"></a><span class="fu">### Feature Selection and Engineering</span></span>
<span id="cb13-119"><a href="#cb13-119" aria-hidden="true" tabindex="-1"></a>Finally, we perform feature selection and engineering. This process involves choosing the most relevant features and possibly creating new features to improve our model's performance.</span>
<span id="cb13-120"><a href="#cb13-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-121"><a href="#cb13-121" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Correlation Analysis**: First, we can perform a correlation analysis to understand the relationships between different features. This helps in identifying features that are strongly correlated with each other, from which we can select the most relevant ones.</span>
<span id="cb13-122"><a href="#cb13-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-125"><a href="#cb13-125" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-126"><a href="#cb13-126" aria-hidden="true" tabindex="-1"></a><span class="co"># Now perform the correlation analysis on the numerical data</span></span>
<span id="cb13-127"><a href="#cb13-127" aria-hidden="true" tabindex="-1"></a>corr <span class="op">=</span> sample_data_encoded.corr()</span>
<span id="cb13-128"><a href="#cb13-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-129"><a href="#cb13-129" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a heatmap</span></span>
<span id="cb13-130"><a href="#cb13-130" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb13-131"><a href="#cb13-131" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">".2f"</span>)</span>
<span id="cb13-132"><a href="#cb13-132" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-133"><a href="#cb13-133" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-134"><a href="#cb13-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-135"><a href="#cb13-135" aria-hidden="true" tabindex="-1"></a><span class="in">    This code generates a heatmap of the correlations between different features. High correlation values suggest a strong relationship, which can inform feature selection.</span></span>
<span id="cb13-136"><a href="#cb13-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-137"><a href="#cb13-137" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Principal Component Analysis (PCA)**: PCA is a technique used to reduce the dimensionality of the data, enhancing the interpretability while minimizing information loss.</span>
<span id="cb13-138"><a href="#cb13-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-141"><a href="#cb13-141" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-142"><a href="#cb13-142" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb13-143"><a href="#cb13-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-144"><a href="#cb13-144" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="fl">0.95</span>) <span class="co"># Retain 95% of the variance</span></span>
<span id="cb13-145"><a href="#cb13-145" aria-hidden="true" tabindex="-1"></a>principal_components <span class="op">=</span> pca.fit_transform(scaled_data)</span>
<span id="cb13-146"><a href="#cb13-146" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-147"><a href="#cb13-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-148"><a href="#cb13-148" aria-hidden="true" tabindex="-1"></a><span class="in">    This code applies PCA to the scaled data, reducing the number of features while retaining 95% of the variance in the data.</span></span>
<span id="cb13-149"><a href="#cb13-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-150"><a href="#cb13-150" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Feature Engineering**: If applicable, you can create new features that might be more indicative of anomalies. For example, creating a composite air quality index from multiple pollutants.</span>
<span id="cb13-151"><a href="#cb13-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-154"><a href="#cb13-154" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-155"><a href="#cb13-155" aria-hidden="true" tabindex="-1"></a>sample_data[<span class="st">'Air_Quality_Index'</span>] <span class="op">=</span> sample_data[<span class="st">'PM2.5'</span>] <span class="op">*</span> <span class="fl">0.4</span> <span class="op">+</span> sample_data[<span class="st">'PM10'</span>] <span class="op">*</span> <span class="fl">0.2</span> <span class="op">+</span> sample_data[<span class="st">'NO2'</span>] <span class="op">*</span> <span class="fl">0.2</span> <span class="op">+</span> sample_data[<span class="st">'SO2'</span>] <span class="op">*</span> <span class="fl">0.1</span> <span class="op">+</span> sample_data[<span class="st">'CO'</span>] <span class="op">*</span> <span class="fl">0.1</span></span>
<span id="cb13-156"><a href="#cb13-156" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-157"><a href="#cb13-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-158"><a href="#cb13-158" aria-hidden="true" tabindex="-1"></a><span class="in">    This code creates a new feature, 'Air_Quality_Index', as a weighted sum of various pollutants, hypothesizing that this composite index might be a more effective predictor of anomalies.</span></span>
<span id="cb13-159"><a href="#cb13-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-160"><a href="#cb13-160" aria-hidden="true" tabindex="-1"></a>Through these steps, we refine our dataset to include the most relevant features for anomaly detection, enhancing the model's accuracy and efficiency.</span>
<span id="cb13-161"><a href="#cb13-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-162"><a href="#cb13-162" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model Training and Evaluation</span></span>
<span id="cb13-163"><a href="#cb13-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-164"><a href="#cb13-164" aria-hidden="true" tabindex="-1"></a>In this phase of our project, we focus on training and evaluating anomaly detection models using the preprocessed air pollution dataset. Here's how we approached this critical stage:</span>
<span id="cb13-165"><a href="#cb13-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-166"><a href="#cb13-166" aria-hidden="true" tabindex="-1"></a><span class="fu">### Dataset Splitting</span></span>
<span id="cb13-167"><a href="#cb13-167" aria-hidden="true" tabindex="-1"></a>Firstly, the dataset is divided into training and test sets. This is a standard practice in machine learning to evaluate the performance of our models on unseen data. Typically, we split the data into around 70-80% for training and the remaining 20-30% for testing.</span>
<span id="cb13-168"><a href="#cb13-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-171"><a href="#cb13-171" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-172"><a href="#cb13-172" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb13-173"><a href="#cb13-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-174"><a href="#cb13-174" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the dataset</span></span>
<span id="cb13-175"><a href="#cb13-175" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> train_test_split(sample_data_encoded, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb13-176"><a href="#cb13-176" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-177"><a href="#cb13-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-178"><a href="#cb13-178" aria-hidden="true" tabindex="-1"></a>In this code, <span class="in">`train_test_split`</span> from <span class="in">`sklearn.model_selection`</span> is used to randomly split the dataset, ensuring a mix of data points in both sets.</span>
<span id="cb13-179"><a href="#cb13-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-180"><a href="#cb13-180" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training Process</span></span>
<span id="cb13-181"><a href="#cb13-181" aria-hidden="true" tabindex="-1"></a>For the training process, we select suitable anomaly detection algorithms. In this project, we consider models like Isolation Forest, One-Class SVM, and others. Here's an example of training an Isolation Forest model:</span>
<span id="cb13-182"><a href="#cb13-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-185"><a href="#cb13-185" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-186"><a href="#cb13-186" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> IsolationForest</span>
<span id="cb13-187"><a href="#cb13-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-188"><a href="#cb13-188" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Isolation Forest model</span></span>
<span id="cb13-189"><a href="#cb13-189" aria-hidden="true" tabindex="-1"></a>iso_forest <span class="op">=</span> IsolationForest(n_estimators<span class="op">=</span><span class="dv">100</span>, contamination<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb13-190"><a href="#cb13-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-191"><a href="#cb13-191" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an imputer object with a strategy to fill NaN values</span></span>
<span id="cb13-192"><a href="#cb13-192" aria-hidden="true" tabindex="-1"></a>imputer <span class="op">=</span> SimpleImputer(strategy<span class="op">=</span><span class="st">'mean'</span>)  <span class="co"># or median, most_frequent</span></span>
<span id="cb13-193"><a href="#cb13-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-194"><a href="#cb13-194" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the imputer to the training data</span></span>
<span id="cb13-195"><a href="#cb13-195" aria-hidden="true" tabindex="-1"></a>X_train_imputed <span class="op">=</span> imputer.fit_transform(X_train)</span>
<span id="cb13-196"><a href="#cb13-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-197"><a href="#cb13-197" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, you can fit the Isolation Forest model</span></span>
<span id="cb13-198"><a href="#cb13-198" aria-hidden="true" tabindex="-1"></a>iso_forest.fit(X_train_imputed)</span>
<span id="cb13-199"><a href="#cb13-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-200"><a href="#cb13-200" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> OneClassSVM</span>
<span id="cb13-201"><a href="#cb13-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-202"><a href="#cb13-202" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the One-Class SVM model</span></span>
<span id="cb13-203"><a href="#cb13-203" aria-hidden="true" tabindex="-1"></a>oc_svm <span class="op">=</span> OneClassSVM(kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb13-204"><a href="#cb13-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-205"><a href="#cb13-205" aria-hidden="true" tabindex="-1"></a><span class="co"># Now you can fit the One-Class SVM model</span></span>
<span id="cb13-206"><a href="#cb13-206" aria-hidden="true" tabindex="-1"></a>oc_svm.fit(X_train_imputed)</span>
<span id="cb13-207"><a href="#cb13-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-208"><a href="#cb13-208" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> LocalOutlierFactor</span>
<span id="cb13-209"><a href="#cb13-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-210"><a href="#cb13-210" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Local Outlier Factor model</span></span>
<span id="cb13-211"><a href="#cb13-211" aria-hidden="true" tabindex="-1"></a>lof <span class="op">=</span> LocalOutlierFactor(n_neighbors<span class="op">=</span><span class="dv">20</span>, contamination<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb13-212"><a href="#cb13-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-213"><a href="#cb13-213" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model on the training data</span></span>
<span id="cb13-214"><a href="#cb13-214" aria-hidden="true" tabindex="-1"></a>lof.fit_predict(X_train_imputed)</span>
<span id="cb13-215"><a href="#cb13-215" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb13-216"><a href="#cb13-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-217"><a href="#cb13-217" aria-hidden="true" tabindex="-1"></a>This code initializes an <span class="in">`Isolation Forest`</span> model with specified parameters and fits it to the training data.</span>
<span id="cb13-218"><a href="#cb13-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-219"><a href="#cb13-219" aria-hidden="true" tabindex="-1"></a><span class="fu">### Model Evaluation</span></span>
<span id="cb13-220"><a href="#cb13-220" aria-hidden="true" tabindex="-1"></a>Evaluating the performance of anomaly detection models can be challenging due to the nature of the data. Common metrics include precision, recall, F1-score, and the ROC curve. These metrics help us understand the trade-offs between correctly identifying anomalies and avoiding false positives.</span>
<span id="cb13-221"><a href="#cb13-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-224"><a href="#cb13-224" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb13-225"><a href="#cb13-225" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix, roc_auc_score</span>
<span id="cb13-226"><a href="#cb13-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-227"><a href="#cb13-227" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict anomalies using the Isolation Forest model</span></span>
<span id="cb13-228"><a href="#cb13-228" aria-hidden="true" tabindex="-1"></a>iso_forest_preds <span class="op">=</span> iso_forest.predict(X_test)</span>
<span id="cb13-229"><a href="#cb13-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-230"><a href="#cb13-230" aria-hidden="true" tabindex="-1"></a><span class="co"># The model outputs -1 for outliers and 1 for inliers. Convert to 0s and 1s (0 for normal, 1 for anomaly)</span></span>
<span id="cb13-231"><a href="#cb13-231" aria-hidden="true" tabindex="-1"></a>iso_forest_preds <span class="op">=</span> [<span class="dv">1</span> <span class="cf">if</span> x <span class="op">==</span> <span class="op">-</span><span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> x <span class="kw">in</span> iso_forest_preds]</span>
<span id="cb13-232"><a href="#cb13-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-233"><a href="#cb13-233" aria-hidden="true" tabindex="-1"></a><span class="co"># Print out the evaluation metrics</span></span>
<span id="cb13-234"><a href="#cb13-234" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Isolation Forest Evaluation:"</span>)</span>
<span id="cb13-235"><a href="#cb13-235" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, iso_forest_preds))</span>
<span id="cb13-236"><a href="#cb13-236" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Confusion Matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, iso_forest_preds))</span>
<span id="cb13-237"><a href="#cb13-237" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ROC AUC Score:"</span>, roc_auc_score(y_test, iso_forest_preds))</span>
<span id="cb13-238"><a href="#cb13-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-239"><a href="#cb13-239" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict anomalies using the One-Class SVM model</span></span>
<span id="cb13-240"><a href="#cb13-240" aria-hidden="true" tabindex="-1"></a>oc_svm_preds <span class="op">=</span> oc_svm.predict(X_test)</span>
<span id="cb13-241"><a href="#cb13-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-242"><a href="#cb13-242" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert predictions to 0s and 1s</span></span>
<span id="cb13-243"><a href="#cb13-243" aria-hidden="true" tabindex="-1"></a>oc_svm_preds <span class="op">=</span> [<span class="dv">1</span> <span class="cf">if</span> x <span class="op">==</span> <span class="op">-</span><span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> x <span class="kw">in</span> oc_svm_preds]</span>
<span id="cb13-244"><a href="#cb13-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-245"><a href="#cb13-245" aria-hidden="true" tabindex="-1"></a><span class="co"># Print out the evaluation metrics</span></span>
<span id="cb13-246"><a href="#cb13-246" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"One-Class SVM Evaluation:"</span>)</span>
<span id="cb13-247"><a href="#cb13-247" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, oc_svm_preds))</span>
<span id="cb13-248"><a href="#cb13-248" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Confusion Matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, oc_svm</span>
<span id="cb13-249"><a href="#cb13-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-250"><a href="#cb13-250" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict anomalies using the LOF model</span></span>
<span id="cb13-251"><a href="#cb13-251" aria-hidden="true" tabindex="-1"></a>lof_preds <span class="op">=</span> lof.fit_predict(X_test)</span>
<span id="cb13-252"><a href="#cb13-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-253"><a href="#cb13-253" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert predictions to 0s and 1s</span></span>
<span id="cb13-254"><a href="#cb13-254" aria-hidden="true" tabindex="-1"></a>lof_preds <span class="op">=</span> [<span class="dv">1</span> <span class="cf">if</span> x <span class="op">==</span> <span class="op">-</span><span class="dv">1</span> <span class="cf">else</span> <span class="dv">0</span> <span class="cf">for</span> x <span class="kw">in</span> lof_preds]</span>
<span id="cb13-255"><a href="#cb13-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-256"><a href="#cb13-256" aria-hidden="true" tabindex="-1"></a><span class="co"># Print out the evaluation metrics</span></span>
<span id="cb13-257"><a href="#cb13-257" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Local Outlier Factor Evaluation:"</span>)</span>
<span id="cb13-258"><a href="#cb13-258" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, lof_preds))</span>
<span id="cb13-259"><a href="#cb13-259" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Confusion Matrix:</span><span class="ch">\n</span><span class="st">"</span>, confusion_matrix(y_test, lof_preds))</span>
<span id="cb13-260"><a href="#cb13-260" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC AUC might not be applicable for LOF if it does not provide probability scores</span></span>
<span id="cb13-261"><a href="#cb13-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-262"><a href="#cb13-262" aria-hidden="true" tabindex="-1"></a>```</span>
<span id="cb13-263"><a href="#cb13-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-264"><a href="#cb13-264" aria-hidden="true" tabindex="-1"></a>This code segment predicts anomalies on the test <span class="bu">set</span> <span class="kw">and</span> then uses functions like `classification_report` <span class="kw">and</span> `roc_auc_score` <span class="im">from</span> `sklearn.metrics` to evaluate the model.</span>
<span id="cb13-265"><a href="#cb13-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-266"><a href="#cb13-266" aria-hidden="true" tabindex="-1"></a><span class="co">### Insights from the Analysis</span></span>
<span id="cb13-267"><a href="#cb13-267" aria-hidden="true" tabindex="-1"></a>The results <span class="im">from</span> the model evaluation provide insights into the effectiveness of our anomaly detection approach. For example, a high precision score indicates that the model <span class="kw">is</span> effective at identifying true anomalies, <span class="cf">while</span> a high recall score shows that it can detect a majority of the actual anomalies present <span class="kw">in</span> the test data. The ROC AUC score helps us understand the model<span class="st">'s ability to distinguish between normal and anomalous data points.</span></span>
<span id="cb13-268"><a href="#cb13-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-269"><a href="#cb13-269" aria-hidden="true" tabindex="-1"></a><span class="er">By carefully analyzing these metrics, we can gauge the success of our models and understand areas for improvement in future iterations of the project.</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>