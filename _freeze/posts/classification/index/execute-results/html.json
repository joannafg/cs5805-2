{
  "hash": "f0be849fbcb592a3ffcdf05c14f2a808",
  "result": {
    "markdown": "---\ntitle: Classification\nauthor: Joanna Fang\ndate: '2023-11-30'\ncategories:\n  - ml\n  - code\n  - classification\n  - driving\n  - kaggle\nformat:\n  html:\n    toc: true\n    code-block-bg: '#FFFFFF'\n    code-block-border-left: '#E83283'\n    code-tools:\n      source: true\n      toggle: false\n      caption: none\n---\n\n# Classification: Predictive Analytics for Driving Behavior Classification\n\n![](thumbnail.jpg){width=\"50%\" fig-align=\"center\"}\n\n## Project Introduction\n\nWelcome to our exploration into the world of machine learning and its application in predicting driving behaviors. In this project, we dive into the realm of vehicular safety, aiming to leverage sensor data to classify driving patterns into three categories: SLOW, NORMAL, and AGGRESSIVE. This endeavor is not just a technical challenge but a crucial step towards enhancing road safety and reducing traffic accidents.\n\n### Objective\nThe primary goal of this project is to accurately predict driving behaviors using data from commonly available sensors in smartphones. By analyzing accelerometer and gyroscope data, we aim to classify driving styles into SLOW, NORMAL, or AGGRESSIVE, contributing significantly to the prevention of road mishaps.\n\n### Importance and Applications\nThe importance of this project is underscored by the alarming statistics from the AAA Foundation for Traffic Safety, highlighting that over half of fatal crashes involve aggressive driving actions. Through this project, we offer a scalable and readily deployable solution to monitor and predict dangerous driving behaviors, potentially saving lives and making our roads safer. Applications of this model extend to insurance companies for risk assessment, ride-sharing services for driver monitoring, and personal safety apps to alert drivers of their driving patterns.\n\n## Data Collection and Description\n\n### Source of the Data\nThe dataset for this project is derived from a real-world scenario, specifically designed to capture driving behaviors. Utilizing a data collector application on Android devices, we have gathered sensor readings directly relevant to driving dynamics.\n\n### Dataset Description\nThe dataset is a rich collection of sensor data recorded from a Samsung Galaxy S21, chosen for its advanced sensor capabilities. Here's a breakdown of the dataset features:\n\n#### Acceleration Data\n- Axes: X, Y, Z\n- Unit: Meters per second squared (m/s²)\n- Note: Gravitational acceleration has been filtered out to focus on the acceleration caused by driving actions.\n\n#### Rotation Data\n- Axes: X, Y, Z\n- Unit: Degrees per second (°/s)\n- Purpose: Captures the angular changes during driving, indicative of turns and maneuvers.\n\n#### Classification Label\n- Categories: SLOW, NORMAL, AGGRESSIVE\n- Basis: The driving behavior classification based on the sensor data patterns.\n\n#### Additional Information\n- Sampling Rate: 2 samples per second, ensuring a fine-grained capture of driving dynamics.\n- Timestamp: Included for each sample, allowing for temporal analysis of driving patterns.\n\nIn the following sections, we will delve into the preprocessing, exploratory analysis, and modeling of this dataset to build a robust classifier for driving behaviors. Stay tuned as we unravel the insights hidden within this data and develop a machine learning model with the potential to make a real-world impact.\n\n## Data Preprocessing\n\nIn the realm of machine learning, data preprocessing is a critical step in preparing raw data for modeling. Our datasets, `motion_data_1.csv` (test data) and `motion_data_2.csv` (train data), contain acceleration and rotation measurements alongside driving behavior classifications. Let's walk through the preprocessing steps:\n\n### Handling Missing Values\n\nFirst, we'll check for missing values in both datasets. Missing data can significantly impact the performance of a machine learning model. If missing values are found, strategies such as imputation or removal of the affected rows can be considered.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\n# Load the datasets\ntest_data = pd.read_csv('motion_data_1.csv')\ntrain_data = pd.read_csv('motion_data_2.csv')\n\n# Checking for missing values in both datasets\nmissing_values_test = test_data.isnull().sum()\nmissing_values_train = train_data.isnull().sum()\n```\n:::\n\n\n### Normalizing or Scaling the Data\n\nNormalization or scaling is crucial when dealing with sensor data. It ensures that each feature contributes proportionately to the final prediction. Given the different scales of acceleration (in m/s²) and rotation (in °/s), applying a scaling method like Min-Max scaling or Standardization is important.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler\n\n# Standardizing the data\nscaler = StandardScaler()\ntrain_data_scaled = scaler.fit_transform(train_data.iloc[:, :-2]) # Excluding 'Class' and 'Timestamp' columns\ntest_data_scaled = scaler.transform(test_data.iloc[:, :-2])\n```\n:::\n\n\n### Feature Engineering \n\nFeature engineering might involve creating new features or modifying existing ones to improve model performance. In our case, we might consider deriving features like the total magnitude of acceleration or rotation.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\n\n# Adding a feature: Total magnitude of acceleration\ntrain_data['TotalAcc'] = np.sqrt(train_data['AccX']**2 + train_data['AccY']**2 + train_data['AccZ']**2)\ntest_data['TotalAcc'] = np.sqrt(test_data['AccX']**2 + test_data['AccY']**2 + test_data['AccZ']**2)\n```\n:::\n\n\n## Exploratory Data Analysis (EDA)\n\n### Statistical Summary of the Dataset\n\nUnderstanding the basic statistics of the dataset is essential. This includes measures like mean, median, standard deviation, etc., providing insights into the data distribution.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# Descriptive statistics of the training data\ntrain_data_description = train_data.describe()\n```\n:::\n\n\n### Visualization of Data Distribution\n\n#### Histograms or Box Plots for Acceleration and Rotation Data\n\nHistograms and box plots are effective for visualizing the distribution of sensor data and identifying outliers or skewness in the data.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Setting up the figure for multiple subplots\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 15))\nfig.suptitle('Histograms of Acceleration and Rotation Data', fontsize=16)\n\n# Plotting histograms for each sensor data column\nsns.histplot(train_data['AccX'], kde=True, ax=axes[0, 0], color='skyblue')\naxes[0, 0].set_title('Acceleration in X-axis (AccX)')\n\nsns.histplot(train_data['AccY'], kde=True, ax=axes[0, 1], color='olive')\naxes[0, 1].set_title('Acceleration in Y-axis (AccY)')\n\nsns.histplot(train_data['AccZ'], kde=True, ax=axes[1, 0], color='gold')\naxes[1, 0].set_title('Acceleration in Z-axis (AccZ)')\n\nsns.histplot(train_data['GyroX'], kde=True, ax=axes[1, 1], color='teal')\naxes[1, 1].set_title('Rotation in X-axis (GyroX)')\n\nsns.histplot(train_data['GyroY'], kde=True, ax=axes[2, 0], color='salmon')\naxes[2, 0].set_title('Rotation in Y-axis (GyroY)')\n\nsns.histplot(train_data['GyroZ'], kde=True, ax=axes[2, 1], color='violet')\naxes[2, 1].set_title('Rotation in Z-axis (GyroZ)')\n\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=1430 height=1373}\n:::\n:::\n\n\n1. **Acceleration (AccX, AccY, AccZ)**: The distributions for acceleration on all three axes appear to be roughly bell-shaped, indicating that most of the readings are clustered around the mean, with fewer readings at the extreme ends. This suggests normal driving conditions with occasional variances that could indicate moments of acceleration or deceleration.\n\n2. **Rotation (GyroX, GyroY, GyroZ)**: The rotation data histograms show a similar bell-shaped distribution, especially for the X and Y axes, indicating consistent turning behavior with some outliers potentially representing more aggressive turns or corrections. The GyroZ histogram is notably narrower, which might suggest that rotation around the Z-axis (often corresponding to yaw movements) is less variable during normal driving conditions.\n\n#### Correlation Heatmaps\n\nA correlation heatmap helps in understanding the relationships between different sensor readings. It's crucial for identifying features that are highly correlated and might need to be addressed during feature selection.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# For the correlation heatmap, we need to exclude non-numeric columns (Class and Timestamp)\ntrain_data_numeric = train_data.select_dtypes(include=['float64', 'int64'])\n\n# Generating the correlation heatmap\nplt.figure(figsize=(10, 6))\nsns.heatmap(train_data_numeric.corr(), annot=True, cmap='coolwarm')\nplt.title('Correlation Heatmap of Numeric Features')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=799 height=505}\n:::\n:::\n\n\nIn this heatmap:\n\n- Values close to 1 or -1 indicate a strong positive or negative correlation, respectively.\n- Values close to 0 suggest no linear correlation between the variables.\n\nIt appears that:\n\n- There are no exceptionally strong correlations between the different axes of acceleration and rotation, which is desirable in a dataset used for behavior prediction as it indicates that the sensor readings provide unique information.\n- The strongest negative correlation is observed between GyroZ and AccX, which might suggest that certain types of aggressive driving behaviors cause inverse changes in these two measurements.\n\nThe absence of very high correlations means that there may not be redundant features in the dataset, which is good for a machine learning model that relies on diverse data points to make predictions. However, the subtle correlations that do exist can still provide valuable insights when developing features and training models.\n\nThese visualizations and their interpretations are key in understanding the underlying patterns in the driving behavior dataset, which will inform the feature selection and modeling phases of the machine learning project.\n\nIn the next sections, we will delve into model selection, training, and evaluation, using the insights and data preparations we've just discussed. Stay tuned!\n\n## Data Preparation for Modeling\n\nPreparing the data for modeling is a crucial step in the machine learning pipeline. It ensures that the data fed into the model is clean, representative, and well-formatted.\n\n### Splitting Data into Training and Testing Sets\n\nWe have two datasets: `train_data` and `test_data`, pre-split for our convenience. Typically, we would use a function like `train_test_split` from `scikit-learn` to divide our dataset into a training set and a test set, ensuring that both sets are representative of the overall distribution. However, in this scenario, that step is already accounted for.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Since the data is pre-split, this step is not required for our current workflow.\n# Normally, we would do something like this:\n# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n```\n:::\n\n\n### Handling Class Imbalance\n\nClass imbalance can significantly skew the performance of a classifier towards the majority class. It's important to check the balance of classes and apply techniques such as resampling if necessary.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Checking the balance of the classes\nclass_counts = train_data['Class'].value_counts()\n\n# If imbalance is found, we might consider resampling strategies like:\n# - Upsampling minority classes\n# - Downsampling majority classes\n# - Using SMOTE (Synthetic Minority Over-sampling Technique)\n```\n:::\n\n\n## Model Selection\n\nSelecting the right model is about finding the balance between prediction accuracy, computational efficiency, and the ease of interpretation.\n\n### Overview of Potential Machine Learning Models for Classification\n\nFor our classification task, we have several models at our disposal:\n\n- **Decision Tree**: A good baseline that is easy to interpret.\n- **Random Forest**: An ensemble method that can improve on the performance of a single decision tree.\n- **Support Vector Machine (SVM)**: Effective in high-dimensional spaces.\n- **Neural Networks**: Potentially high performance but may require more data and compute resources.\n\n### Criteria for Model Selection\n\nWhen selecting the model, we consider several criteria:\n\n- **Accuracy**: How often the model makes the correct prediction.\n- **Speed**: How quickly the model can be trained and used for prediction.\n- **Interpretability**: The ease with which we can understand the model's predictions.\n\n## Model Training\n\nTraining our models is like teaching them to understand patterns within the data that distinguish between SLOW, NORMAL, and AGGRESSIVE driving behaviors. We will employ four different machine learning models to find the best predictor.\n\n### Training Different Models\n\nWe start by training different types of models. Each has its own strengths and might capture different aspects of the driving behavior.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\n\n# Initializing models with default parameters\ndecision_tree = DecisionTreeClassifier()\nrandom_forest = RandomForestClassifier()\nsvm = SVC()\nneural_network = MLPClassifier()\n\ndecision_tree.fit(train_data.drop(['Class'], axis=1), train_data['Class'])\nrandom_forest.fit(train_data.drop(['Class'], axis=1), train_data['Class'])\nsvm.fit(train_data.drop(['Class'], axis=1), train_data['Class']) \nneural_network.fit(train_data.drop(['Class'], axis=1), train_data['Class'])\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\nThe `fit` method allows the models to learn from the training data. It's during this process that they identify which features are most important for predicting driving behavior.\n\n### Hyperparameter Tuning\n\nTo optimize our models, we tweak their settings, known as hyperparameters. This process is akin to fine-tuning an instrument to ensure it plays the perfect note.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\n\n# Setting up the parameter grid for a Decision Tree\nparam_grid = {\n    'decision_tree': {\n        'max_depth': [10, 20, 30],\n        'min_samples_leaf': [1, 2, 4]\n    }\n    # Parameter grids for other models can be set up similarly\n}\n\n# Hyperparameter tuning for the Decision Tree using GridSearchCV\ngrid_search_dt = GridSearchCV(decision_tree, param_grid['decision_tree'], cv=5)\ngrid_search_dt.fit(train_data.drop(['Class'], axis=1), train_data['Class'])\nbest_params_dt = grid_search_dt.best_params_\n\n# We would perform GridSearchCV for each model type with its respective parameter grid\n```\n:::\n\n\nUsing `GridSearchCV`, we systematically work through multiple combinations of parameter tunes, cross-validating as we go to determine which tune gives the best performance.\n\nBy the end of these steps, we will have trained four different models and optimized their hyperparameters for best performance. This careful tuning is what sets the stage for the final step: evaluating these models to select the ultimate candidate for our driving behavior prediction task.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}