{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Linear and Nonlinear Regression\n",
        "author: Joanna Fang\n",
        "date: '2023-11-29'\n",
        "categories:\n",
        "  - ml\n",
        "  - code\n",
        "  - linear regression\n",
        "  - nonlinear regression\n",
        "  - driving\n",
        "  - kaggle\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    code-block-bg: '#FFFFFF'\n",
        "    code-block-border-left: '#E83283'\n",
        "    code-tools:\n",
        "      source: true\n",
        "      toggle: false\n",
        "      caption: none\n",
        "---"
      ],
      "id": "31cc056a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting Air Pollutant Concentrations Using Linear and Random Forest Regression: A Jupyter Notebook Guide\n",
        "\n",
        "![](thumbnail.jpg){width=\"50%\" fig-align=\"center\"}\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Air quality is a critical environmental factor impacting public health, ecosystem sustainability, and the global climate. Pollutants such as particulate matter (PM2.5 and PM10), sulfur dioxide (SO2), nitrogen dioxide (NO2), carbon monoxide (CO), and ozone (O3) can have severe health impacts, including respiratory and cardiovascular diseases. Understanding and predicting the concentrations of these pollutants is essential for creating effective environmental policies and public health interventions.\n",
        "\n",
        "In this blog, we'll delve into two powerful statistical methods used in predicting air pollutant concentrations: linear regression and Random Forest regression.\n",
        "\n",
        "### Linear Regression\n",
        "Linear regression is a fundamental statistical approach used to model the relationship between a dependent variable and one or more independent variables. In the context of air quality, it helps us understand how various environmental factors like temperature, humidity, and wind speed influence pollutant levels. The model assumes a linear relationship between the variables, which can be represented as:\n",
        "\n",
        "$$\n",
        "Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_nX_n + \\epsilon\n",
        "$$\n",
        "\n",
        "Here, \\( Y \\) is the pollutant concentration we want to predict, \\( X_1, X_2, ..., X_n \\) are the environmental factors, \\( \\beta_0, \\beta_1, ..., \\beta_n \\) are the coefficients to be estimated, and \\( \\epsilon \\) is the error term.\n",
        "\n",
        "### Random Forest Regression\n",
        "Random Forest, on the other hand, is a type of ensemble learning method, particularly useful for non-linear relationships. It operates by constructing multiple decision trees during training and outputting the mean prediction of the individual trees. This method is beneficial for handling complex interactions between variables and can provide more accurate predictions for complex datasets like those in air quality studies.\n",
        "\n",
        "The purpose of this blog is to provide a step-by-step guide on how to use these methods, utilizing a Jupyter Notebook, to predict pollutant concentrations. We'll start by exploring our dataset, `air_data_all.csv`, which includes a variety of environmental conditions and temporal factors, and then apply these regression techniques to gain insights into the factors affecting air quality.\n",
        "\n",
        "By the end of this blog, you'll have a clearer understanding of how to implement these techniques in Python and interpret their results, equipping you with the tools needed for insightful environmental data analysis.\n",
        "\n",
        "## 1. Examining the Dataset\n",
        "\n",
        "Before diving into the regression models, it's crucial to understand the dataset we'll be working with. The dataset, named `air_data_all.csv`, is a comprehensive collection of air quality measurements.\n",
        "\n",
        "### Dataset Description and Relevance\n",
        "This dataset is a rich source of information, capturing various environmental conditions and pollutant concentrations. It includes temporal data (year, month, day, hour) and readings of several key air pollutants (PM2.5, PM10, SO2, NO2, CO, O3). Additionally, it records several meteorological factors like temperature (TEMP), pressure (PRES), dew point temperature (DEWP), precipitation (RAIN), wind direction (wd), and wind speed (WSPM). Such datasets are crucial for studying the dynamics of air pollution and its dependency on different environmental and temporal factors.\n",
        "\n",
        "### Introduction to Database Columns\n",
        "Each column in this dataset plays a specific role:\n",
        "\n",
        "1. **Temporal Data (year, month, day, hour)**: Helps in understanding the variation in pollutant levels over different times of the day, months, or years.\n",
        "2. **Pollutant Concentrations (PM2.5, PM10, SO2, NO2, CO, O3)**: These are the primary pollutants, usually monitored in urban air quality studies.\n",
        "3. **Meteorological Data (TEMP, PRES, DEWP, RAIN, wd, WSPM)**: Weather conditions can significantly influence pollutant dispersion and concentration.\n",
        "4. **Station**: Identifies the monitoring site, which can be key in studying geographical variations in air quality.\n",
        "\n",
        "### Initial Observations and Potential Challenges\n",
        "Upon initial examination of the dataset, we observe the comprehensive nature of the data, which is excellent for a detailed analysis. However, we might face certain challenges:\n",
        "\n",
        "- **Missing Data**: Air quality datasets often have missing values, which need careful handling to avoid bias in the models.\n",
        "- **High Dimensionality**: With many variables, the risk of multicollinearity increases, where two or more variables are highly correlated.\n",
        "- **Non-linear Relationships**: Not all relationships between the pollutants and environmental factors might be linear, necessitating the use of more complex models like Random Forest.\n",
        "\n",
        "In the following sections, we'll address these challenges as we prepare the data for regression analysis. By the end of this process, we'll be ready to apply linear and Random Forest regression to predict pollutant concentrations effectively.\n",
        "\n",
        "## 2. Selecting Target Pollutants\n",
        "\n",
        "In our journey to understand and predict air quality, selecting the right target pollutants is crucial. For this analysis, we will focus on the following pollutants: PM2.5, PM10, SO2, NO2, CO, and O3. Let's delve into the criteria and rationale behind choosing these specific pollutants.\n",
        "\n",
        "### Criteria for Selecting Target Pollutants\n",
        "The selection of target pollutants is based on the following criteria:\n",
        "\n",
        "1. **Health Impact**: Pollutants known to have significant health effects are prioritized.\n",
        "2. **Prevalence and Relevance**: Common pollutants in urban and industrial areas are selected due to their higher relevance.\n",
        "3. **Data Availability**: Pollutants with consistent and reliable data within the dataset are chosen to ensure the accuracy of the analysis.\n",
        "\n",
        "### Rationale Behind the Selection\n",
        "Each selected pollutant has its unique importance in air quality analysis:\n",
        "\n",
        "- **PM2.5 and PM10 (Particulate Matter)**: These are tiny particles in the air that reduce visibility and cause the air to appear hazy when levels are elevated. PM2.5 and PM10 are known for their ability to penetrate deep into the lungs and even into the bloodstream, causing respiratory and cardiovascular issues.\n",
        "\n",
        "- **SO2 (Sulfur Dioxide)**: A gas typically produced by burning fossil fuels containing sulfur. It's associated with acid rain and has health implications, especially for individuals with asthma.\n",
        "\n",
        "- **NO2 (Nitrogen Dioxide)**: Primarily gets into the air from the burning of fuel. NO2 forms from emissions from cars, trucks and buses, power plants, and off-road equipment. It's linked to various respiratory problems.\n",
        "\n",
        "- **CO (Carbon Monoxide)**: A colorless, odorless gas that is harmful when inhaled in large amounts. It's released from vehicles and other combustion sources and can cause harmful health effects by reducing the amount of oxygen that can be transported in the bloodstream.\n",
        "\n",
        "- **O3 (Ozone)**: At ground level, ozone is a harmful air pollutant and a significant component of smog. It's not emitted directly into the air but is created by chemical reactions between oxides of nitrogen (NOx) and volatile organic compounds (VOC) in the presence of sunlight.\n",
        "\n",
        "By focusing on these pollutants, we can provide a comprehensive analysis of air quality and its health implications. Next, we will perform correlation analysis and multicollinearity checks to understand how these pollutants interact with each other and with different environmental factors.\n",
        "\n",
        "## 3. Data Cleaning and Transformation\n",
        "\n",
        "Before delving into sophisticated regression models, it's imperative to prepare our dataset, \"air_data_all.csv,\" for analysis. This stage, known as data cleaning and transformation, involves several key steps to ensure the data's integrity and usability.\n",
        "\n",
        "### Identifying and Handling Missing or Inconsistent Data\n",
        "The initial step in data preprocessing is to identify and address any missing (NaN) or inconsistent data. This is crucial as such data can significantly skew our analysis.\n"
      ],
      "id": "0a5fc442"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install seaborn\n",
        "!{sys.executable} -m pip install matplotlib\n",
        "!{sys.executable} -m pip install statsmodels\n",
        "!{sys.executable} -m pip install scikit-learn\n",
        "!{sys.executable} -m pip install pandas\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "sample_data = pd.read_csv('air_data_all.csv')\n",
        "\n",
        "# Identifying missing or infinite values\n",
        "sample_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Checking for missing values\n",
        "missing_values = sample_data.isnull().sum()"
      ],
      "id": "5c72fdfe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this code block, we first replace any infinite values with NaNs. Then, we calculate the number of missing values in each column. Depending on the nature and volume of missing data, we can either fill these gaps using statistical methods (like mean, median) or consider removing the rows/columns entirely.\n",
        "\n",
        "### Normalization or Standardization of Data\n",
        "Normalization (rescaling data to a range, like 0–1) and standardization (shifting the distribution to have a mean of zero and a standard deviation of one) are crucial for models sensitive to the scale of data, such as linear regression.\n"
      ],
      "id": "fd5dbee8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardizing the dataset\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(sample_data[['TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']])\n",
        "\n",
        "# Converting scaled data back to a DataFrame for further use\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=['TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM'])"
      ],
      "id": "868b5b6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we use `StandardScaler` from Scikit-learn to standardize the continuous variables such as temperature and pressure. This process aligns the data onto one scale, removing bias due to different units or scales.\n",
        "\n",
        "### Transforming Categorical Data into a Usable Format\n",
        "Many regression models require numerical input, so transforming categorical data into a numerical format is essential.\n"
      ],
      "id": "12a3f39c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Creating dummy variables for categorical data\n",
        "wd_dummies = pd.get_dummies(sample_data['wd'])\n",
        "sample_data = pd.concat([sample_data, wd_dummies], axis=1)"
      ],
      "id": "22bae2c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the above snippet, we create dummy variables for the `wd` column (wind direction), converting it into a format that can be efficiently processed by regression algorithms.\n",
        "\n",
        "### Visuals Showing Before and After Data Transformation\n",
        "Visualizations are effective for demonstrating the impact of data transformation. For instance, before and after standardization, we can plot histograms of a variable to observe changes in its distribution.\n"
      ],
      "id": "05b155eb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting before and after standardization\n",
        "plt.hist(sample_data['TEMP'], bins=30, alpha=0.5, label='Original TEMP')\n",
        "plt.hist(scaled_df['TEMP'], bins=30, alpha=0.5, label='Standardized TEMP')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "264b7c51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This histogram allows us to compare the distribution of the temperature data before and after standardization, showcasing the effects of our data transformation steps.\n",
        "\n",
        "By completing these data cleaning and transformation processes, we ensure that our dataset is primed for accurate and effective regression analysis, laying a solid foundation for our subsequent modeling steps.\n",
        "\n",
        "## 4. Correlation Analysis and Multicollinearity Check\n",
        "\n",
        "After preparing our dataset, the next step in our analysis involves understanding the relationships between variables using correlation analysis and checking for multicollinearity. These steps are critical for ensuring the reliability and interpretability of our regression models.\n",
        "\n",
        "### Correlation Analysis and Its Importance\n",
        "Correlation analysis helps us understand the strength and direction of the relationship between two variables. In regression analysis, it's important to identify how independent variables are related to the dependent variable and to each other.\n"
      ],
      "id": "32201f63"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Removing missing or infinite values from the scaled dataset\n",
        "scaled_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "scaled_df.dropna(inplace=True)\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculating the correlation matrix for key variables\n",
        "corr_matrix = sample_data[['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']].corr()\n",
        "\n",
        "# Visualizing the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title(\"Correlation Matrix of Environmental Factors and Pollutants\")\n",
        "plt.show()"
      ],
      "id": "cd23fdbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this code, we calculate and visualize the correlation matrix of key pollutants and environmental factors. This heatmap provides a clear visual representation of the relationships, where the color intensity and the value in each cell indicate the strength and direction of the correlation.\n",
        "\n",
        "### Multicollinearity Check and Its Implications\n",
        "Multicollinearity occurs when two or more independent variables in a regression model are highly correlated. This can lead to unreliable coefficient estimates, making it difficult to determine the effect of each independent variable.\n"
      ],
      "id": "7a8c0518"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Preparing data for multicollinearity check\n",
        "features = scaled_df[['TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']]\n",
        "\n",
        "# Calculating VIF for each feature\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data['Feature'] = features.columns\n",
        "vif_data['VIF'] = [variance_inflation_factor(features.values, i) for i in range(features.shape[1])]\n",
        "\n",
        "vif_data"
      ],
      "id": "b009d58a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we calculate the Variance Inflation Factor (VIF) for each feature. A VIF value greater than 5 or 10 indicates high multicollinearity, suggesting that the variable could be linearly predicted from the others with a substantial degree of accuracy.\n",
        "\n",
        "### Visual Representation of Correlation and Multicollinearity Findings\n",
        "Visualizing these statistics can help in better understanding and communicating the findings.\n"
      ],
      "id": "9ac35cf3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualizing VIF values\n",
        "plt.bar(vif_data['Feature'], vif_data['VIF'])\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Variance Inflation Factor (VIF)')\n",
        "plt.title('Multicollinearity Check - VIF Values')\n",
        "plt.show()"
      ],
      "id": "85504c9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This bar chart provides a clear representation of the VIF values for each feature, helping us identify which variables might be contributing to multicollinearity in the model.\n",
        "\n",
        "By conducting both correlation analysis and a multicollinearity check, we ensure the integrity and effectiveness of our regression models, setting a strong foundation for accurate and insightful analysis of the factors influencing air quality.\n",
        "\n",
        "### Feature Selection\n",
        "Based on the results of Correlation Analysis and Multicollinearity Check. I decided to predict SO2 with 'TEMP', 'PRES', 'DEWP'. \n",
        "\n",
        "## 5. Linear Regression Analysis\n",
        "\n",
        "In this section, we will apply linear regression analysis to predict the concentration of sulfur dioxide (SO2) based on three key environmental factors: 'TEMP', 'PRES', and 'DEWP'. Linear regression is a fundamental statistical method used to understand the relationship between a dependent variable and one or more independent variables.\n",
        "\n",
        "### Introduction to Linear Regression and Its Applicability\n",
        "Linear regression is a widely used statistical technique for modeling and analyzing the relationship between a scalar response (dependent variable) and one or more explanatory variables (independent variables). The method assumes a linear relationship between the variables. In our context, we will use linear regression to understand how temperature ('TEMP'), pressure ('PRES'), and dew point ('DEWP') affect the concentration of SO2 in the air.\n",
        "\n",
        "### Step-by-Step Linear Regression Analysis Using Jupyter Notebook\n",
        "Now, let's conduct a linear regression analysis using Python in a Jupyter Notebook environment.\n"
      ],
      "id": "536c6bdd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Filter out rows where any of the feature columns or 'SO2' is NaN\n",
        "filtered_data = sample_data.dropna(subset=['TEMP', 'PRES', 'DEWP', 'SO2'])\n",
        "\n",
        "# Standardizing the relevant columns of the filtered data\n",
        "scaler = StandardScaler()\n",
        "scaled_columns = scaler.fit_transform(filtered_data[['TEMP', 'PRES', 'DEWP']])\n",
        "\n",
        "# Converting scaled data back to a DataFrame\n",
        "scaled_df = pd.DataFrame(scaled_columns, columns=['TEMP', 'PRES', 'DEWP'])\n",
        "\n",
        "# Defining features (X) and target variable (y)\n",
        "X = scaled_df\n",
        "y = filtered_data['SO2']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Creating and fitting the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Creating the linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fitting the model to the training data\n",
        "model.fit(X_train, y_train)"
      ],
      "id": "8d8d0b4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this code, we first select our features and target variable, split the data into training and test sets, create a Linear Regression model, and then fit it to our training data.\n",
        "\n",
        "### Visual Representation of Linear Regression Results and Plotting the Best Fit Line\n",
        "Visualizing the model's predictions in comparison with the actual values is crucial for assessing its performance. We'll also plot the best-fit line to better understand the linear relationship.\n"
      ],
      "id": "9fb1b4b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predicting SO2 values for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "plt.xlim(0, 200)\n",
        "plt.ylim(0, 40)\n",
        "\n",
        "# Visualizing the actual vs predicted values and the best-fit line\n",
        "plt.scatter(y_test, y_pred, alpha=0.6, color='blue')  # Actual vs Predicted scatter plot\n",
        "plt.xlabel('Actual SO2')\n",
        "plt.ylabel('Predicted SO2')\n",
        "plt.title('Actual vs Predicted SO2 Concentrations')\n",
        "\n",
        "# Plotting the best-fit line\n",
        "plt.plot(np.unique(y_test), np.poly1d(np.polyfit(y_test, y_pred, 1))(np.unique(y_test)), color='red')\n",
        "\n",
        "plt.show()"
      ],
      "id": "a8cf97c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The scatter plot shows the actual vs. predicted SO2 values, and the red line represents the linear fit, providing a visual indication of how well the model predicts SO2 concentration.\n",
        "\n",
        "### Evaluating the Performance of the Linear Regression Model\n",
        "Finally, we evaluate the performance of our model using common statistical metrics.\n"
      ],
      "id": "1e461caf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Computing performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R² Score: {r2}\")"
      ],
      "id": "50907bcf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Mean Squared Error (MSE) provides an average of the squares of the errors, essentially quantifying the difference between predicted and actual values. The R² Score measures the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
        "\n",
        "By following these steps, we can use linear regression to effectively predict environmental factors' impact on air quality, specifically sulfur dioxide concentrations, and evaluate the accuracy of our predictions."
      ],
      "id": "69283a64"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}